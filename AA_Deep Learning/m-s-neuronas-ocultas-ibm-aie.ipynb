{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"2f5ce9afcc812bed49b055553e1299aeb7fdc15bcf650afcdd418c93503bc66f","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Neural Networks More Hidden Neurons</h1>\n","metadata":{}},{"cell_type":"markdown","source":"<h2>Objective</h2><ul><li> How to create complex Neural Network in pytorch.</li></ul> \n","metadata":{}},{"cell_type":"markdown","source":"<h2>Table of Contents</h2>\n\n<ul>\n    <li><a href=\"#Prep\">Preparation</a></li>\n    <li><a href=\"#Data\">Get Our Data</a></li>\n    <li><a href=\"#Train\">Define the Neural Network, Optimizer, and Train the Model</a></li>\n</ul>\n<p>Estimated Time Needed: <strong>25 min</strong></p>\n\n<hr>\n","metadata":{}},{"cell_type":"markdown","source":"\n<a name=\"Prep\"><h2 id=\"Prep\">Preparation</h2></a>\n","metadata":{}},{"cell_type":"markdown","source":"We'll need to import the following libraries for this lab.\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define the plotting functions.\n","metadata":{}},{"cell_type":"code","source":"def get_hist(model,data_set):\n    activations=model.activation(data_set.x)\n    for i,activation in enumerate(activations):\n        plt.hist(activation.numpy(),4,density=True)\n        plt.title(\"Activation layer \" + str(i+1))\n        plt.xlabel(\"Activation\")\n        plt.xlabel(\"Activation\")\n        plt.legend()\n        plt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def PlotStuff(X,Y,model=None,leg=False):\n    \n    plt.plot(X[Y==0].numpy(),Y[Y==0].numpy(),'or',label='training points y=0 ' )\n    plt.plot(X[Y==1].numpy(),Y[Y==1].numpy(),'ob',label='training points y=1 ' )\n\n    if model!=None:\n        plt.plot(X.numpy(),model(X).detach().numpy(),label='neral network ')\n\n    plt.legend()\n    plt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a name=\"Data\"><h2 id=\"Data\">Get Our Data</h2></a>\n","metadata":{}},{"cell_type":"markdown","source":"Define the class to get our dataset.\n","metadata":{}},{"cell_type":"code","source":"class Data(Dataset):\n    def __init__(self):\n        self.x=torch.linspace(-20, 20, 100).view(-1,1)\n  \n        self.y=torch.zeros(self.x.shape[0])\n        self.y[(self.x[:,0]>-10)& (self.x[:,0]<-5)]=1\n        self.y[(self.x[:,0]>5)& (self.x[:,0]<10)]=1\n        self.y=self.y.view(-1,1)\n        self.len=self.x.shape[0]\n    def __getitem__(self,index):    \n            \n        return self.x[index],self.y[index]\n    def __len__(self):\n        return self.len\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a name=\"Train\"><h2 id=\"Train\">Define the Neural Network, Optimizer and Train the Model</h2></a>\n","metadata":{}},{"cell_type":"markdown","source":"Define the class for creating our model.\n","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self,D_in,H,D_out):\n        super(Net,self).__init__()\n        self.linear1=nn.Linear(D_in,H)\n        self.linear2=nn.Linear(H,D_out)\n\n        \n    def forward(self,x):\n        x=torch.sigmoid(self.linear1(x))  \n        x=torch.sigmoid(self.linear2(x))\n        return x","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the function to train our model, which accumulate lost for each iteration to obtain the cost.\n","metadata":{}},{"cell_type":"code","source":" def train(data_set,model,criterion, train_loader, optimizer, epochs=5,plot_number=10):\n    cost=[]\n    \n    for epoch in range(epochs):\n        total=0\n        \n        for x,y in train_loader:\n            optimizer.zero_grad()\n            \n            yhat=model(x)\n            loss=criterion(yhat,y)\n            loss.backward()\n            optimizer.step()\n            total+=loss.item()\n            \n        if epoch%plot_number==0:\n            PlotStuff(data_set.x,data_set.y,model)\n        \n        cost.append(total)\n    plt.figure()\n    plt.plot(cost)\n    plt.xlabel('epoch')\n    plt.ylabel('cost')\n    plt.show()\n    return cost","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_set=Data()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"PlotStuff(data_set.x,data_set.y,leg=False)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create our model with 9\nneurons in the hidden layer. And then create a BCE loss and an Adam optimizer.\n","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(0)\nmodel=Net(1,9,1)\nlearning_rate=0.1\ncriterion=nn.BCELoss()\noptimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)\ntrain_loader=DataLoader(dataset=data_set,batch_size=100)\nCOST=train(data_set,model,criterion, train_loader, optimizer, epochs=600,plot_number=200)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"raw","source":"# this is for exercises\nmodel= torch.nn.Sequential(\n    torch.nn.Linear(1, 6), \n    torch.nn.Sigmoid(),\n    torch.nn.Linear(6,1),\n    torch.nn.Sigmoid()\n\n)","metadata":{}},{"cell_type":"code","source":"plt.plot(COST)","metadata":{},"outputs":[],"execution_count":null}]}