{"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"ae8ba0cf2893803ad4014e07cd6f441eb4d2116642d0236ea59413b42123d00f","kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Test Uniform, Default and Xavier Uniform Initialization on MNIST dataset with tanh activation</h1>\n","metadata":{}},{"cell_type":"markdown","source":"\n<h3>Objective for this Notebook<h3>    \n<h5> 1. Define Several Neural Network, Criterion function, Optimizer</h5>\n<h5> 2. Test Uniform, Default and Xavier Initialization </h5>     \n\n","metadata":{}},{"cell_type":"markdown","source":"<h2>Table of Contents</h2>\nIn this lab, you will test PyTroch Default Initialization, Xavier Initialization and Uniform Initialization on the MNIST dataset. \n\n<ul>\n    <li><a href=\"#Model\">Neural Network Module and Training Function</a></li>\n    <li><a href=\"#Make\">Make Some Data</a></li>\n    <li><a href=\"#Cost\">Define Several Neural Network, Criterion function, Optimizer</a></li>\n    <li><a href=\"#Train\">Test Uniform, Default and Xavier Initialization</a></li>\n    <li><a href=\"#Result\">Analyze Results</a></li>\n</ul>\n\n<p>Estimated Time Needed: <strong>25 min</strong></p>\n\n<hr>\n","metadata":{}},{"cell_type":"markdown","source":"<h2>Preparation</h2>\n","metadata":{}},{"cell_type":"markdown","source":"We'll need the following libraries:  \n","metadata":{}},{"cell_type":"code","source":"# Import the libraries we need to use in this lab\n\n# Using the following line code to install the torchvision library\n# !mamba install -y torchvision\n\nimport torch \nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\nimport matplotlib.pylab as plt\nimport numpy as np\n\ntorch.manual_seed(0)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name=\"Model\"><h2 id=\"Model\">Neural Network Module and Training Function</h2> </a>\n","metadata":{}},{"cell_type":"markdown","source":"Define the neural network module or class with Xavier Initialization\n","metadata":{}},{"cell_type":"code","source":"# Define the neural network with Xavier initialization\n\nclass Net_Xavier(nn.Module):\n    \n    # Constructor\n    def __init__(self, Layers):\n        super(Net_Xavier, self).__init__()\n        self.hidden = nn.ModuleList()\n\n        for input_size, output_size in zip(Layers, Layers[1:]):\n            linear = nn.Linear(input_size, output_size)\n            torch.nn.init.xavier_uniform_(linear.weight)\n            self.hidden.append(linear)\n    \n    # Prediction\n    def forward(self, x):\n        L = len(self.hidden)\n        for (l, linear_transform) in zip(range(L), self.hidden):\n            if l < L - 1:\n                x = torch.tanh(linear_transform(x))\n            else:\n                x = linear_transform(x)\n        return x","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define the neural network module with Uniform Initialization:\n","metadata":{}},{"cell_type":"code","source":"# Define the neural network with Uniform initialization\n\nclass Net_Uniform(nn.Module):\n    \n    # Constructor\n    def __init__(self, Layers):\n        super(Net_Uniform, self).__init__()\n        self.hidden = nn.ModuleList()\n\n        for input_size, output_size in zip(Layers, Layers[1:]):\n            linear = nn.Linear(input_size, output_size)\n            linear.weight.data.uniform_(0, 1)\n            self.hidden.append(linear)\n    \n    # Prediction\n    def forward(self, x):\n        L = len(self.hidden)\n        for (l, linear_transform) in zip(range(L), self.hidden):\n            if l < L - 1:\n                x = torch.tanh(linear_transform(x))\n            else:\n                x = linear_transform(x)\n        return x","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define the neural network module with PyTroch Default Initialization\n","metadata":{}},{"cell_type":"code","source":"# Define the neural network with Default initialization\n\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, Layers):\n        super(Net, self).__init__()\n        self.hidden = nn.ModuleList()\n\n        for input_size, output_size in zip(Layers, Layers[1:]):\n            linear = nn.Linear(input_size, output_size)\n            self.hidden.append(linear)\n    \n    # Prediction\n    def forward(self, x):\n        L = len(self.hidden)\n        for (l, linear_transform) in zip(range(L), self.hidden):\n            if l < L - 1:\n                x = torch.tanh(linear_transform(x))\n            else:\n                x = linear_transform(x)\n        return x","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define a function to train the model, in this case the function returns a Python dictionary to store the training loss and accuracy on the validation data \n","metadata":{}},{"cell_type":"code","source":"# function to Train the model\n\ndef train(model, criterion, train_loader, validation_loader, optimizer, epochs = 100):\n    i = 0\n    loss_accuracy = {'training_loss':[], 'validation_accuracy':[]}  \n    \n    for epoch in range(epochs):\n        for i,(x, y) in enumerate(train_loader):\n            optimizer.zero_grad()\n            z = model(x.view(-1, 28 * 28))\n            loss = criterion(z, y)\n            loss.backward()\n            optimizer.step()\n            loss_accuracy['training_loss'].append(loss.data.item())\n            \n        correct = 0\n        for x, y in validation_loader:\n            yhat = model(x.view(-1, 28 * 28))\n            _, label = torch.max(yhat, 1)\n            correct += (label==y).sum().item()\n        accuracy = 100 * (correct / len(validation_dataset))\n        loss_accuracy['validation_accuracy'].append(accuracy)\n        \n    return loss_accuracy","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name=\"Make\"><h2 id=\"Makeup_Data\">Make Some Data</h2></a>\n","metadata":{}},{"cell_type":"markdown","source":"Load the training dataset by setting the parameters <code>train </code> to <code>True</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>\n","metadata":{}},{"cell_type":"code","source":"# Create the train dataset\n\ntrain_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load the testing dataset by setting the parameters <code>train</code> to <code>False</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>\n","metadata":{}},{"cell_type":"code","source":"# Create the validation dataset\n\nvalidation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the training-data loader and the validation-data loader object \n","metadata":{}},{"cell_type":"code","source":"# Create Dataloader for both train dataset and validation dataset\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name=\"Cost\"><h2 id=\"Cost\">Define Neural Network, Criterion function, Optimizer and Train the Model</h2></a>\n","metadata":{}},{"cell_type":"markdown","source":"Create the criterion function\n","metadata":{}},{"cell_type":"code","source":"# Define criterion function\n\ncriterion = nn.CrossEntropyLoss()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the model with 100 hidden layers  \n","metadata":{}},{"cell_type":"code","source":"# Set the parameters\n\ninput_dim = 28 * 28\noutput_dim = 10\nlayers = [input_dim, 100, 10, 100, 10, 100, output_dim]\nepochs = 15","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name=\"Train\"><h2 id=\"Train\">Test PyTorch Default Initialization, Xavier Initialization, Uniform Initialization</h2></a>\n","metadata":{}},{"cell_type":"markdown","source":"Train the network using PyTorch Default Initialization\n","metadata":{}},{"cell_type":"code","source":"# Train the model with default initialization\n\nmodel = Net(layers)\nlearning_rate = 0.01\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\ntraining_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=epochs)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train the network using Xavier Initialization function\n","metadata":{}},{"cell_type":"code","source":"# Train the model with Xavier initialization\n\nmodel_Xavier = Net_Xavier(layers)\noptimizer = torch.optim.SGD(model_Xavier.parameters(), lr=learning_rate)\ntraining_results_Xavier = train(model_Xavier, criterion, train_loader, validation_loader, optimizer, epochs=epochs)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train the network using Uniform Initialization\n","metadata":{}},{"cell_type":"code","source":"# Train the model with Uniform initialization\n\nmodel_Uniform = Net_Uniform(layers)\noptimizer = torch.optim.SGD(model_Uniform.parameters(), lr=learning_rate)\ntraining_results_Uniform = train(model_Uniform, criterion, train_loader, validation_loader, optimizer, epochs=epochs)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name=\"Result\"><h2 id=\"Result\">Analyse Results</h2></a>\n","metadata":{}},{"cell_type":"markdown","source":"Compare the training loss for each initialization\n","metadata":{}},{"cell_type":"code","source":"# Plot the loss\n\nplt.plot(training_results_Xavier['training_loss'], label='Xavier')\nplt.plot(training_results['training_loss'], label='Default')\nplt.plot(training_results_Uniform['training_loss'], label='Uniform')\nplt.ylabel('loss')\nplt.xlabel('iteration ')  \nplt.title('training loss iterations')\nplt.legend()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"compare the validation loss for each model  \n","metadata":{}},{"cell_type":"code","source":"# Plot the accuracy\n\nplt.plot(training_results_Xavier['validation_accuracy'], label='Xavier')\nplt.plot(training_results['validation_accuracy'], label='Default')\nplt.plot(training_results_Uniform['validation_accuracy'], label='Uniform') \nplt.ylabel('validation accuracy')\nplt.xlabel('epochs')   \nplt.legend()","metadata":{},"outputs":[],"execution_count":null}]}