{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"6e8b02b0ed908655b3491ae0062ae590473763ac9c81fc4eeeaaf5b7091883a3","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Deep Neural Networks</h1>\n","metadata":{}},{"cell_type":"markdown","source":"\n<h3>Objective for this Notebook<h3>    \n<h5> 1. Define Several Neural Network, Criterion function, Optimizer.</h5>\n<h5> 2. Test Sigmoid,Tanh and Relu. </h5>\n<h5> 3. Analyse Results. </h5>     \n\n","metadata":{}},{"cell_type":"markdown","source":"<h2>Table of Contents</h2>\n<p>In this lab, you will test Sigmoid, Tanh and Relu activation functions on the MNIST dataset with two hidden Layers.</p>\n\n<ul>\n    <li><a href=\"#Model\">Neural Network Module and Training Function</a></li>\n    <li><a href=\"#Makeup_Data\">Make Some Data</a></li>\n    <li><a href=\"#Train\">Define Several Neural Network, Criterion function, Optimizer</a></li>\n    <li><a href=\"#Test\">Test Sigmoid,Tanh and Relu </a></li>\n    <li><a href=\"#Result\">Analyse Results</a></li>\n</ul>\n<p>Estimated Time Needed: <strong>25 min</strong></p>\n\n<hr>\n","metadata":{}},{"cell_type":"markdown","source":"We'll need the following libraries\n","metadata":{}},{"cell_type":"code","source":"# Import the libraries we need for this lab\n\n# Using the following line code to install the torchvision library\n# !mamba install -y torchvision\n\n!pip install torchvision==0.9.1 torch==1.8.1 \nimport torch \nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\nimport torch.nn.functional as F\nimport matplotlib.pylab as plt\nimport numpy as np\ntorch.manual_seed(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name=\"Model\"><h2 id=\"Model\">Neural Network Module and Training Function</h2></a>\n","metadata":{}},{"cell_type":"markdown","source":"Define the neural network module or class, with two hidden Layers \n","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://ibm.box.com/shared/static/5wtclahun0f70qlwkn2kxzh3amnbq4zg.png\" width=\"200\" alt=\"Neural Network Model\">\n","metadata":{}},{"cell_type":"code","source":"# Create the model class using sigmoid as the activation function\n\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, D_in, H1, H2, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H1)\n        self.linear2 = nn.Linear(H1, H2)\n        self.linear3 = nn.Linear(H2, D_out)\n    \n    # Prediction\n    def forward(self,x):\n        x = torch.sigmoid(self.linear1(x)) \n        x = torch.sigmoid(self.linear2(x))\n        x = self.linear3(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define the class with the Tanh activation function \n","metadata":{}},{"cell_type":"code","source":"# Create the model class using Tanh as a activation function\n\nclass NetTanh(nn.Module):\n    \n    # Constructor\n    def __init__(self, D_in, H1, H2, D_out):\n        super(NetTanh, self).__init__()\n        self.linear1 = nn.Linear(D_in, H1)\n        self.linear2 = nn.Linear(H1, H2)\n        self.linear3 = nn.Linear(H2, D_out)\n    \n    # Prediction\n    def forward(self, x):\n        x = torch.tanh(self.linear1(x))\n        x = torch.tanh(self.linear2(x))\n        x = self.linear3(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define the class for the Relu activation function \n","metadata":{}},{"cell_type":"code","source":"# Create the model class using Relu as a activation function\n\nclass NetRelu(nn.Module):\n    \n    # Constructor\n    def __init__(self, D_in, H1, H2, D_out):\n        super(NetRelu, self).__init__()\n        self.linear1 = nn.Linear(D_in, H1)\n        self.linear2 = nn.Linear(H1, H2)\n        self.linear3 = nn.Linear(H2, D_out)\n    \n    # Prediction\n    def forward(self, x):\n        x = torch.relu(self.linear1(x))  \n        x = torch.relu(self.linear2(x))\n        x = self.linear3(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define a function to  train the model, in this case the function returns a Python dictionary to store the training loss and accuracy on the validation data \n","metadata":{}},{"cell_type":"code","source":"# Train the model\n\ndef train(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n    i = 0\n    useful_stuff = {'training_loss': [], 'validation_accuracy': []}  \n    \n    for epoch in range(epochs):\n        for i, (x, y) in enumerate(train_loader):\n            optimizer.zero_grad()\n            z = model(x.view(-1, 28 * 28))\n            loss = criterion(z, y)\n            loss.backward()\n            optimizer.step()\n            useful_stuff['training_loss'].append(loss.data.item())\n        \n        correct = 0\n        for x, y in validation_loader:\n            z = model(x.view(-1, 28 * 28))\n            _, label = torch.max(z, 1)\n            correct += (label == y).sum().item()\n    \n        accuracy = 100 * (correct / len(validation_dataset))\n        useful_stuff['validation_accuracy'].append(accuracy)\n    \n    return useful_stuff","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name=\"Makeup_Data\"><h2 id=\"Makeup_Data\">Make Some Data</h2></a>\n","metadata":{}},{"cell_type":"markdown","source":"Load the training dataset by setting the parameters <code>train</code> to <code>True</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>\n","metadata":{}},{"cell_type":"code","source":"# Create the training dataset\n\ntrain_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load the testing dataset by setting the parameters <code>train</code> to <code>False</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>\n","metadata":{}},{"cell_type":"code","source":"# Create the validating dataset\n\nvalidation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the criterion function  \n","metadata":{}},{"cell_type":"code","source":"# Create the criterion function\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the training-data loader and the validation-data loader object \n","metadata":{}},{"cell_type":"code","source":"# Create the training data loader and validation data loader object\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name=\"Train\"><h2 id=\"Train\">Define Neural Network, Criterion function, Optimizer and Train the Model</h2></a> \n","metadata":{}},{"cell_type":"markdown","source":"Create  the model with 100 hidden layers  \n","metadata":{}},{"cell_type":"code","source":"# Set the parameters for create the model\n\ninput_dim = 28 * 28\nhidden_dim1 = 50\nhidden_dim2 = 50\noutput_dim = 10","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The epoch number in the video is 35. You can try 10 for now. If you try 35, it may take a long time.\n","metadata":{}},{"cell_type":"code","source":"# Set the number of iterations\n\ncust_epochs = 10","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name=\"Test\"><h2 id=\"Test\">Test Sigmoid ,Tanh and Relu</h2></a>\n","metadata":{}},{"cell_type":"markdown","source":"Train the network using the Sigmoid activation function\n","metadata":{}},{"cell_type":"code","source":"# Train the model with sigmoid function\n\nlearning_rate = 0.01\nmodel = Net(input_dim, hidden_dim1, hidden_dim2, output_dim)\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\ntraining_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=cust_epochs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train the network using the Tanh activation function\n","metadata":{}},{"cell_type":"code","source":"# Train the model with tanh function\n\nlearning_rate = 0.01\nmodel_Tanh = NetTanh(input_dim, hidden_dim1, hidden_dim2, output_dim)\noptimizer = torch.optim.SGD(model_Tanh.parameters(), lr=learning_rate)\ntraining_results_tanch = train(model_Tanh, criterion, train_loader, validation_loader, optimizer, epochs=cust_epochs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train the network using the Relu activation function\n","metadata":{}},{"cell_type":"code","source":"# Train the model with relu function\n\nlearning_rate = 0.01\nmodelRelu = NetRelu(input_dim, hidden_dim1, hidden_dim2, output_dim)\noptimizer = torch.optim.SGD(modelRelu.parameters(), lr=learning_rate)\ntraining_results_relu = train(modelRelu, criterion, train_loader, validation_loader, optimizer, epochs=cust_epochs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name=\"Result\"><h2 id=\"Result\">Analyze Results</h2></a>\n","metadata":{}},{"cell_type":"markdown","source":"Compare the training loss for each activation \n","metadata":{}},{"cell_type":"code","source":"# Compare the training loss\n\nplt.plot(training_results_tanch['training_loss'], label='tanh')\nplt.plot(training_results['training_loss'], label='sigmoid')\nplt.plot(training_results_relu['training_loss'], label='relu')\nplt.ylabel('loss')\nplt.title('training loss iterations')\nplt.legend()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Compare the validation loss for each model  \n","metadata":{}},{"cell_type":"code","source":"# Compare the validation loss\n\nplt.plot(training_results_tanch['validation_accuracy'], label = 'tanh')\nplt.plot(training_results['validation_accuracy'], label = 'sigmoid')\nplt.plot(training_results_relu['validation_accuracy'], label = 'relu') \nplt.ylabel('validation accuracy')\nplt.xlabel('Iteration')   \nplt.legend()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}