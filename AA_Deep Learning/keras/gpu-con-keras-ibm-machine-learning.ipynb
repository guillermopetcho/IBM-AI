{"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **GPU with Keras**\n","metadata":{}},{"cell_type":"markdown","source":"Estimated time needed: **25** minutes\n","metadata":{}},{"cell_type":"markdown","source":"You may have heard of GPUs (Graphics Processing Unit) and CPUs (Central Processing Unit), but what is the difference? GPUs have been commonly seen used by gamers for better visual rendering, but nowadays its applications extend way beyond improving videogame experience. With respect to deep learning, GPUs are extremely helpful by speeding up certain computations. The difference is evident especially for models that train on large datasets, in which the researcher can take advantage of parallel computing to run operations simultaneously and save time. In this lab, you will learn about how to utilize GPU for `tensorflow`, specifically `keras`.\n","metadata":{}},{"cell_type":"markdown","source":"<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module6/L1/img_GPU.jpeg\" width=\"600\" alt=\"computer components\">\n<center>\n","metadata":{}},{"cell_type":"markdown","source":"**_Note_**: Skills Network Labs currently doesn't have any GPUs available. In order to test the difference between CPU and GPU, please run this lab on a local machine or environment that has GPUs.\n","metadata":{}},{"cell_type":"markdown","source":"## __Table of Contents__\n\n<ol>\n    <li><a href=\"#Objectives\">Objectives</a></li>\n    <li>\n        <a href=\"#Setup\">Setup</a>\n        <ol>\n            <li><a href=\"#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n            <li><a href=\"#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n            <li><a href=\"#Defining-Helper-Functions\">Defining Helper Functions</a></li>\n        </ol>\n    </li>\n    <li>\n        <a href=\"#Benefits-of-Using-GPU\">Benefits of Using GPU</a>\n    </li>  \n    <li>\n        <a href=\"#Using-CPU\">Using CPU</a>\n    </li> \n    <li>\n        <a href=\"#Using-GPU\">Using GPU</a>\n        <ol>\n            <li><a href=\"#Check-Availability\">Check Availability</a></li>\n            <li><a href=\"#Choosing-Specific-GPUs\">Choosing Specific GPUs</a></li>\n        </ol>    \n    </li>\n    <li>\n        <a href=\"#Using-CPU-and-GPU-jointly\">Using CPU and GPU jointly</a>\n    </li>     \n</ol>\n","metadata":{}},{"cell_type":"markdown","source":"## Objectives\n\nAfter completing this lab you will be able to:\n\n - Set environment to CPU/GPU\n - Control usage of CPU/GPU in parts of the code\n","metadata":{}},{"cell_type":"markdown","source":"----\n","metadata":{}},{"cell_type":"markdown","source":"## Setup\n","metadata":{}},{"cell_type":"markdown","source":"For this lab, we will be using the following libraries:\n\n*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and machine-learning-pipeline related functions.\n*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for visualizing the data.\n*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n","metadata":{}},{"cell_type":"markdown","source":"### Installing Required Libraries\n\nThe following required libraries are pre-installed in the Skills Network Labs environment. However, if you run these notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda), you will need to install these libraries by removing the `#` sign before `!mamba` and before `!pip install --upgrade tensorflow` in the code cells below.\n","metadata":{}},{"cell_type":"code","source":"# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%capture\n!pip install --upgrade tensorflow -qqq","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Importing Required Libraries\n\n_We recommend you import all required libraries in one place, as follows:_\n","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter('ignore')\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n\nimport numpy as np\n\nimport tensorflow as tf\n# Import the keras library\nfrom tensorflow import keras\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nfrom tensorflow.python.client import device_lib","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Benefits of Using GPU\n","metadata":{}},{"cell_type":"markdown","source":"GPU excels in parallel computing in comparison to CPU. This technique is especially useful for deep learning algorithms, such as building a Convolutional Neural Network (CNN), or as a matter of fact, any neural network. An example of a parallel processing task is performing convolution on an input layer, in which the kernel is multiplied with the input layer matrix, one local region at a time.\n\nThe runtime difference is especially noticeable when you train a CNN with multiple epochs - tasks where a lot of matrix operations are involved!\n","metadata":{}},{"cell_type":"markdown","source":"## Using CPU\n","metadata":{}},{"cell_type":"markdown","source":"By default, `tensorflow` searches for available GPU to use. There are two ways to force your machine to ignore all GPUs and run code with CPU instead.\n","metadata":{}},{"cell_type":"markdown","source":"If you want the entire code/notebook to run on CPU, you can specify the environment _**before**_ importing tensorflow/keras. If you decide to switch back, you can restart the kernel and run import as usual without the line below.\n","metadata":{}},{"cell_type":"code","source":"# Specify the environment variable value\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If the environment variable `CUDA_VISIBLE_DEVICES` value takes the values 0/1 (or other positive values), the machine is using GPU to run the code. By setting it to -1, it specifies the algorithm to be run with CPU.\n","metadata":{}},{"cell_type":"code","source":"# Check that CPU is used\nprint(os.environ['CUDA_VISIBLE_DEVICES'])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If instead you want to use CPU for portions of the code in a notebook, consider the following approach. Here, you specify what to run with `/CPU:0` using a `with` statement. Using `%%timeit` with `-n1 -r1` will time the process for one pass of the cell. As an example, we'll be training the following CNN on a **DATASET**. Feel free to change the code within the statement to test CPU performance! \n","metadata":{}},{"cell_type":"code","source":"# Import data\n(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reshape the data\nX_train = X_train.reshape((X_train.shape[0],X_train.shape[1],X_train.shape[2],1))\nX_test = X_test.reshape((X_test.shape[0],X_test.shape[1],X_test.shape[2],1))\n\ny_train = y_train.reshape((y_train.shape[0],1))\ny_test = y_test.reshape((y_test.shape[0],1))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%timeit -n1 -r1\n# Building the CNN model and fitting on train data\nwith tf.device('/CPU:0'):\n    model_cpu = Sequential()\n    model_cpu.add(Conv2D(input_shape = (28, 28, 1),\n                     filters=5, \n                     padding='Same',\n                     kernel_size=(3,3)\n                     ))\n    model_cpu.add(MaxPooling2D(pool_size=(2,2)))\n    model_cpu.add(Flatten())\n    model_cpu.add(Dense(256, activation='relu'))\n    model_cpu.add(Dense(10, activation='softmax'))\n    \n    model_cpu.compile(optimizer='adam', \n              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n    \n    model_cpu.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Using GPU\n","metadata":{}},{"cell_type":"markdown","source":"As mentioned above, `tensorflow` automatically searches for GPUs to run on. Let's take a closer look at how we can have more control over that.\n","metadata":{}},{"cell_type":"markdown","source":"### Check Availability\n","metadata":{}},{"cell_type":"markdown","source":"First, you can check the number of GPUs available on the machine. \n","metadata":{}},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If you're running this notebook in Skills Network Lab, you can see that it doesn't have any GPUs available for use. However, if your local machine does have GPU(s), you can try the following code to play with what you want to run on GPU.\n","metadata":{}},{"cell_type":"markdown","source":"### Choosing Specific GPUs\n","metadata":{}},{"cell_type":"markdown","source":"In order to specify a particular GPU to run on, we have to first check what units there are in the environment. The following lists out the information of each device, including the device name, type, memory limit, and so on. \n","metadata":{}},{"cell_type":"code","source":"print(device_lib.list_local_devices())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To specify using a specific GPU, again use `tf.device()` with the `name` as input, just like we did for the CPU case. In the `with` statement, proceed with writing code as usual. Here, we are specifying `tensorflow` to be run on GPU ennumerated #2. We also use `%%timeit` here so you can compare the time that GPU took to run in comparison with CPU!\n","metadata":{}},{"cell_type":"code","source":"%%timeit -n1 -r1\nwith tf.device('/device:GPU:2'):\n    model_gpu = Sequential()\n    model_gpu.add(Conv2D(input_shape = (28, 28, 1),\n                     filters=5, \n                     padding='Same',\n                     kernel_size=(3,3)\n                     ))\n    model_gpu.add(MaxPooling2D(pool_size=(2,2)))\n    model_gpu.add(Flatten())\n    model_gpu.add(Dense(256, activation='relu'))\n    model_gpu.add(Dense(10, activation='softmax'))\n    \n    model_gpu.compile(optimizer='adam', \n              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n    \n    model_gpu.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Using CPU and GPU jointly\n","metadata":{}},{"cell_type":"markdown","source":"What if we want to use _both_ CPU and GPU for different parts of the same python script? Turns out we can do that too! Simply take advantage of the `tf.device()` function again to specify which unit the code fragment should be run on. Below, we show an example of how to run the same matrix operation on multiple GPUs and add up the tensors on CPU.\n","metadata":{}},{"cell_type":"code","source":"# Enable tensor allocations or operations to be printed\ntf.debugging.set_log_device_placement(True)\n\n# Get list of all logical GPUs\ngpus = tf.config.list_logical_devices('GPU')\n\n# Check if there are GPUs on this computer\nif gpus:\n  # Run matrix computation on multiple GPUs\n    c = []\n    for gpu in gpus:\n        with tf.device(gpu.name):\n            a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n            b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]) \n            c.append(tf.matmul(a, b))\n\n    # Run on CPU \n    with tf.device('/CPU:0'):\n        matmul_sum = tf.add_n(c)\n\n    print(matmul_sum)","metadata":{},"outputs":[],"execution_count":null}]}