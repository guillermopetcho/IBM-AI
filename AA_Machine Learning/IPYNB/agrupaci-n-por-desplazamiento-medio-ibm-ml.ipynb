{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**<h1>Mean Shift Clustering </h1>**\n","metadata":{}},{"cell_type":"markdown","source":"Estimated time needed: **30** minutes\n","metadata":{}},{"cell_type":"markdown","source":"As you hike in the mountains, you stumble upon a plant you have never seen before. You look around and you spot a few more of them. The similarities between them tell you that they probably belong to the same group of plants. However, you are not a botanist, so you can't know exactly which species these plants belong to. This task can be solved with the help of clustering analysis. Clustering can identify the groups of similar looking objects and group them together based on their similar instances.\n\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/images/hiking.jpg\" width=\"70%\">\n\nImage from [PxHere](https://pxhere.com/en/photo/1067051?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01)\n","metadata":{}},{"cell_type":"markdown","source":"In this notebook, we will explore Mean Shift Clustering, which is a **non-parametric centroid-based clustering** algorithm. Mean Shift Clustering attempts to group data without having first to be trained on the labeled data. Unlike the K-Means Clustering, when using the Mean Shift, we don't need to specify the number of clusters beforehand. Mean Shift Clustering is used in a wide variety of applications, such as image segmentation, academic ranking systems, search engines, medicine, and many others. \n\nIn the first part of this notebook, we will focus on the image segmentation, which is used in many object detection and tracking systems, as it makes it easier to detect the contour of each object.\n\nIn the second part of this notebook, we will show how to use the Mean Shift Clustering to classify the survivors rates of the Titanic, the most famous shipwreck in history. Based on the passengers' features (e.g. age, ticket class, fare, etc.) we will classify the passengers into clusters with different survival probabilities. \n","metadata":{}},{"cell_type":"markdown","source":"## __Table of Contents__\n\n<ol>\n    <li><a href=\"#Objectives\">Objectives</a></li>\n    <li>\n        <a href=\"#Setup\">Setup</a>\n        <ol>\n            <li><a href=\"#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n            <li><a href=\"#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n        </ol>\n    </li>\n   <li>\n        <a href=\"#Mean Shift for Image Segmentation\">Mean Shift for Image Segmentation</a>\n        <ol>\n            <li><a href=\"#Pre-processing Image\">Pre-processing Image</a></li> \n            <li><a href=\"#Apply Mean Shift to the Image\">Apply Mean Shift to the Image</a></li>         \n        </ol>\n    </li>    \n    <li>\n        <a href=\"#Exercises\">Exercises</a>\n        <ol>\n            <li><a href=\"#Exercise 1 - Repeat the above image segmentation process for a new image on the internet\">Exercise 1 - Repeat the above image segmentation process for a new image on the internet</a></li>\n            <li><a href=\"#Exercise 2 - Mean Shift Applied to the Titanic Dataset \">Exercise 2 - Mean Shift Applied to the Titanic Dataset</a></li>\n        </ol>       \n    </li>\n    <li>\n        <a href=\"#How Mean Shift Works (Optional)\">How Mean Shift Works (Optional)</a>\n        <ol>\n            <li><a href=\"#Kernel Density Estimation\">Kernel Density Estimation</a></li>\n            <li><a href=\"#Mean Shift From Scratch\">Mean Shift From Scratch</a></li>\n        </ol>\n    </li>    \n</ol>\n","metadata":{}},{"cell_type":"markdown","source":"----\n","metadata":{}},{"cell_type":"markdown","source":"<h2>Objectives</h2>\n","metadata":{}},{"cell_type":"markdown","source":"After completing this lab you will be able to:\n","metadata":{}},{"cell_type":"markdown","source":"- **Understand** Kernel Density Estimation (KDE).\n- **Describe** how Mean Shift Works from scratch.\n- **Implement** Mean Shift for image segmentation.\n","metadata":{}},{"cell_type":"markdown","source":"<h2 id='Setup'>Setup</h2>\n","metadata":{}},{"cell_type":"markdown","source":"For this lab, we will be using the following libraries:\n - [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for managing the data.\n - [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for mathematical operations.\n - [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for machine learning and machine-learning-pipeline related functions.\n - [`openCV`](https://opencv.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) OpenCV provides a real-time optimized Computer Vision library, tools, and hardware. \n - [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for additional plotting tools.\n","metadata":{}},{"cell_type":"markdown","source":"### Installing Required Libraries\n\nThe following required modules are pre-installed in the Skills Network Labs environment. However if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda) you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n","metadata":{"tags":[]}},{"cell_type":"code","source":"# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n#!mamba install -qy pandas==1.3.4 numpy==1.21.4 matplotlib==3.5.0 scikit-learn==0.20.1 scipy==1.7.3\n# Note: If your environment doesn't support \"!mamba install\", use \"!pip install pandas==1.3.4 numpy==1.21.4 matplotlib==3.5.0 scikit-learn==0.20.1 scipy==1.7.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:48.382525Z","iopub.execute_input":"2025-07-15T18:17:48.382897Z","iopub.status.idle":"2025-07-15T18:17:48.389548Z","shell.execute_reply.started":"2025-07-15T18:17:48.382870Z","shell.execute_reply":"2025-07-15T18:17:48.388443Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install opencv-python","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:48.391226Z","iopub.execute_input":"2025-07-15T18:17:48.391728Z","iopub.status.idle":"2025-07-15T18:17:53.889012Z","shell.execute_reply.started":"2025-07-15T18:17:48.391691Z","shell.execute_reply":"2025-07-15T18:17:53.887444Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.2->opencv-python) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.2->opencv-python) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.2->opencv-python) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.2->opencv-python) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.2->opencv-python) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Importing Required Libraries\n","metadata":{}},{"cell_type":"code","source":"# Surpress any warnings:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\n\nimport numpy as np\nimport cv2 as cv\nfrom sklearn.cluster import MeanShift, estimate_bandwidth\nfrom mpl_toolkits import mplot3d\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:53.891647Z","iopub.execute_input":"2025-07-15T18:17:53.892027Z","iopub.status.idle":"2025-07-15T18:17:56.460802Z","shell.execute_reply.started":"2025-07-15T18:17:53.891991Z","shell.execute_reply":"2025-07-15T18:17:56.459734Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"<p style=\"color:blue\">If you wish to learn in detail about how Mean Shift works before studying its applications, you can go to <a href=\"#E_1\"> How Mean Shift Works (Optional)</a> section first. </P> \n","metadata":{}},{"cell_type":"markdown","source":"<h2 id=\"Exercise_1\">Mean Shift for Image Segmentation   </h2> \n","metadata":{}},{"cell_type":"markdown","source":"### Pre-processing Image \n","metadata":{}},{"cell_type":"markdown","source":"Mean Shift Clustering can be used for image segmentation. An image segmentation attempts to cluster an image pixels according to their color. It then replaces each pixel's color with the mean color of its cluster. This way considerably reduces the number of different colors in the image. So, each cluster represents the mode or the most common intensities. Every pixel is labeled according to the cluster it’s nearest to. Consider the following image.\n","metadata":{}},{"cell_type":"markdown","source":"Download the image:\n","metadata":{}},{"cell_type":"code","source":"import skillsnetwork\nawait skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/peppers.jpeg\", overwrite=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.461886Z","iopub.execute_input":"2025-07-15T18:17:56.462338Z","iopub.status.idle":"2025-07-15T18:17:56.627456Z","shell.execute_reply.started":"2025-07-15T18:17:56.462278Z","shell.execute_reply":"2025-07-15T18:17:56.623256Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2432870575.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mskillsnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mskillsnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/peppers.jpeg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skillsnetwork'"],"ename":"ModuleNotFoundError","evalue":"No module named 'skillsnetwork'","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"img = cv.imread('peppers.jpeg')\nplt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.628098Z","iopub.status.idle":"2025-07-15T18:17:56.628503Z","shell.execute_reply.started":"2025-07-15T18:17:56.628338Z","shell.execute_reply":"2025-07-15T18:17:56.628354Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We will pre-process the image by smoothing it.  \n","metadata":{}},{"cell_type":"code","source":"img = cv.medianBlur(img, 7)\nplt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.630438Z","iopub.status.idle":"2025-07-15T18:17:56.630996Z","shell.execute_reply.started":"2025-07-15T18:17:56.630730Z","shell.execute_reply":"2025-07-15T18:17:56.630755Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can plot the Red, Green, Blue (RGB) values as 3D points. \n","metadata":{}},{"cell_type":"code","source":"ax = plt.axes(projection =\"3d\")\nax.scatter3D(img[:,:,0],img[:,:,1],img[:,:,2])\nax.set_title('Pixel Values ')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.633183Z","iopub.status.idle":"2025-07-15T18:17:56.633809Z","shell.execute_reply.started":"2025-07-15T18:17:56.633602Z","shell.execute_reply":"2025-07-15T18:17:56.633628Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We have a rectangular image with three channels.   \n","metadata":{}},{"cell_type":"code","source":"img.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.635197Z","iopub.status.idle":"2025-07-15T18:17:56.635557Z","shell.execute_reply.started":"2025-07-15T18:17:56.635410Z","shell.execute_reply":"2025-07-15T18:17:56.635426Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We convert the image to 194 x 259 rows (194 x 259 = 50246, which is the shape of our matrix) for each pixel, and three columns for each color channel (Red, Green, Blue), as a numpy array of <code>X</code>:\n","metadata":{}},{"cell_type":"code","source":"X = img.reshape((-1,3))\nprint(\"shape: \",X.shape)\nprint(\"data type   : \",X.dtype)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.637445Z","iopub.status.idle":"2025-07-15T18:17:56.637876Z","shell.execute_reply.started":"2025-07-15T18:17:56.637662Z","shell.execute_reply":"2025-07-15T18:17:56.637684Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As we see, the data type is `unit8`, so, we need to cast it to be a `float32`:\n","metadata":{}},{"cell_type":"code","source":"X = np.float32(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.638746Z","iopub.status.idle":"2025-07-15T18:17:56.639064Z","shell.execute_reply.started":"2025-07-15T18:17:56.638924Z","shell.execute_reply":"2025-07-15T18:17:56.638942Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Apply Mean Shift to the Image \n","metadata":{}},{"cell_type":"markdown","source":"Estimate the bandwidth to use with the mean-shift algorithm, using the <code>estimate_bandwidth</code> function:\n- <code>X</code>: array-like of shape <code>(n_samples, n_features)</code>\nInput points.\n- <code>quantile</code>: float, default=0.3 Should be between [0, 1], 0.5 means that the median of all pairwise distances is used.\n- <code>n_samples</code>: int, The number of samples to be used. If not given, all samples are to be used.\n","metadata":{}},{"cell_type":"code","source":"bandwidth = estimate_bandwidth(X, quantile=.06, n_samples=3000)\nbandwidth ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.640147Z","iopub.status.idle":"2025-07-15T18:17:56.640500Z","shell.execute_reply.started":"2025-07-15T18:17:56.640358Z","shell.execute_reply":"2025-07-15T18:17:56.640373Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can create a <code>MeanShift</code> object in sklearn with the following parameters:\n- <code>bandwidth</code>:float, default=None\nBandwidth used in the RBF kernel.\n- <code>max_itert</code>: (default=300) Maximum number of iterations per seed point before the clustering operation terminates (for that seed point), if has not converged yet.\n- <code>bin_seeding</code> :if true, initial kernel locations are not locations of all points, but rather the location of the discretized version of points.\n\nWe then fit the model.\n","metadata":{}},{"cell_type":"code","source":"ms = MeanShift(bandwidth=bandwidth,bin_seeding=True)\nms.fit(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.641451Z","iopub.status.idle":"2025-07-15T18:17:56.641755Z","shell.execute_reply.started":"2025-07-15T18:17:56.641610Z","shell.execute_reply":"2025-07-15T18:17:56.641624Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, we have the label corresponding to the label of each row.\n","metadata":{}},{"cell_type":"code","source":"labeled=ms.labels_\nlabeled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.642927Z","iopub.status.idle":"2025-07-15T18:17:56.643219Z","shell.execute_reply.started":"2025-07-15T18:17:56.643084Z","shell.execute_reply":"2025-07-15T18:17:56.643105Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"For each sample, we can find the assigned clusters:\n","metadata":{}},{"cell_type":"code","source":"clusters=ms.predict(X)\nclusters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.645022Z","iopub.status.idle":"2025-07-15T18:17:56.645527Z","shell.execute_reply.started":"2025-07-15T18:17:56.645273Z","shell.execute_reply":"2025-07-15T18:17:56.645316Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can list the unique clusters.  \n","metadata":{}},{"cell_type":"code","source":"np.unique(labeled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.647245Z","iopub.status.idle":"2025-07-15T18:17:56.647647Z","shell.execute_reply.started":"2025-07-15T18:17:56.647498Z","shell.execute_reply":"2025-07-15T18:17:56.647514Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can also list the actual cluster centroid locations, which are also the RGB values:\n","metadata":{}},{"cell_type":"code","source":"ms.cluster_centers_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.650052Z","iopub.status.idle":"2025-07-15T18:17:56.650488Z","shell.execute_reply.started":"2025-07-15T18:17:56.650317Z","shell.execute_reply":"2025-07-15T18:17:56.650340Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can convert the clusters `unit8` datatype for images: \n","metadata":{}},{"cell_type":"code","source":"cluster_int8=np.uint8(ms.cluster_centers_)\ncluster_int8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.651707Z","iopub.status.idle":"2025-07-15T18:17:56.652225Z","shell.execute_reply.started":"2025-07-15T18:17:56.651974Z","shell.execute_reply":"2025-07-15T18:17:56.651997Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can also estimate what cluster each sample belongs to, as follows: \n","metadata":{}},{"cell_type":"code","source":"ms.predict(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.653419Z","iopub.status.idle":"2025-07-15T18:17:56.653752Z","shell.execute_reply.started":"2025-07-15T18:17:56.653606Z","shell.execute_reply":"2025-07-15T18:17:56.653620Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ax = plt.axes(projection =\"3d\")\nax.scatter3D(img[:,:,0],img[:,:,1],img[:,:,2])\nax.set_title('Pixel Values ')\nplt.show()\n\nax = plt.axes(projection =\"3d\")\nax.set_title('Pixel Cluster Values  ')\nax.scatter3D(cluster_int8[:,0],cluster_int8[:,1],cluster_int8[:,2],color='red')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.654739Z","iopub.status.idle":"2025-07-15T18:17:56.655004Z","shell.execute_reply.started":"2025-07-15T18:17:56.654879Z","shell.execute_reply":"2025-07-15T18:17:56.654890Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can assign each data point to the cluster value and reshape it back  to a Rectangular image. \n","metadata":{}},{"cell_type":"code","source":"result=np.zeros(X.shape,dtype=np.uint8)\n\nfor label in np.unique(labeled):\n    result[labeled==label,:]=cluster_int8[label,:]    \n    \n\nresult=result.reshape(img.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.656663Z","iopub.status.idle":"2025-07-15T18:17:56.657165Z","shell.execute_reply.started":"2025-07-15T18:17:56.656938Z","shell.execute_reply":"2025-07-15T18:17:56.656958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(cv.cvtColor(result, cv.COLOR_BGR2RGB))\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.658920Z","iopub.status.idle":"2025-07-15T18:17:56.659256Z","shell.execute_reply.started":"2025-07-15T18:17:56.659106Z","shell.execute_reply":"2025-07-15T18:17:56.659120Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We now plot each cluster, as a cluster value, and we see that each cluster corresponds to a different object. \n","metadata":{}},{"cell_type":"code","source":"for label in np.unique(labeled):\n    result=np.zeros(X.shape,dtype=np.uint8)\n    result[labeled==label,:]=cluster_int8[label,:]  \n    plt.imshow(cv.cvtColor(result.reshape(img.shape), cv.COLOR_BGR2RGB))\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.660868Z","iopub.status.idle":"2025-07-15T18:17:56.661209Z","shell.execute_reply.started":"2025-07-15T18:17:56.661038Z","shell.execute_reply":"2025-07-15T18:17:56.661050Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Therefore, we have classified our images according to their different vegetable types, using the Mean Shift Clustering.\n","metadata":{}},{"cell_type":"markdown","source":"## Exercises\n","metadata":{}},{"cell_type":"code","source":"import requests \nurl='https://www.plastform.ca/wp-content/themes/plastform/images/slider-image-2.jpg'\nname=\"my_file.jpg\"\n\nwith open(name, 'wb') as file:\n    file.write(requests.get(url, stream=True).content)\n    \nimg = cv.imread(name)\nplt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.663392Z","iopub.status.idle":"2025-07-15T18:17:56.663731Z","shell.execute_reply.started":"2025-07-15T18:17:56.663590Z","shell.execute_reply":"2025-07-15T18:17:56.663603Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now it's your turn to play around with the **MeanShift** algorithm.\n","metadata":{}},{"cell_type":"code","source":"img = cv.medianBlur(img, 7)\nplt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\nX = img.reshape((-1,3))\nX = np.float32(X)\nbandwidth = estimate_bandwidth(X, quantile=.06, n_samples=3000)\nms = MeanShift(bandwidth=bandwidth,bin_seeding=True)\nms.fit(X)\nlabeled=ms.labels_\ncluster_int8=np.uint8(ms.cluster_centers_)\nresult=np.zeros(X.shape,dtype=np.uint8)\nlabeled=ms.labels_\nresult=np.zeros(X.shape,dtype=np.uint8)\n\nfor label in np.unique(labeled):\n    result[labeled==label,:]=cluster_int8[label,:]    \n    \n    cluster_int8[label]\nresult=result.reshape(img.shape)\nplt.imshow(cv.cvtColor(result, cv.COLOR_BGR2RGB))\n\nfor label in np.unique(labeled):\n    result=np.zeros(X.shape,dtype=np.uint8)\n    result[labeled==label,:]=cluster_int8[label,:]  \n    plt.imshow(cv.cvtColor(result.reshape(img.shape), cv.COLOR_BGR2RGB))\n    plt.show()\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.665485Z","iopub.status.idle":"2025-07-15T18:17:56.665942Z","shell.execute_reply.started":"2025-07-15T18:17:56.665771Z","shell.execute_reply":"2025-07-15T18:17:56.665789Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Exercise 2 - Mean Shift Applied to the  Titanic Dataset \n","metadata":{}},{"cell_type":"markdown","source":"On April 15, 1912, the  Titanic collided with an iceberg and sank. When the Titanic sank, it killed 1502 out of 2224 passengers and crew. In this section you will apply Mean-Shift clustering on features such as age, gender, class, etc. We will then determine if there is a relationship between survival and the different clusters. The following table summarizes the data:\n","metadata":{}},{"cell_type":"markdown","source":"<table>\n<tbody>\n<tr><th><b>Variable</b></th><th><b>Definition</b></th><th><b>Key</b></th></tr>\n<tr>\n<td>survival</td>\n<td>Survival</td>\n<td>0 = No, 1 = Yes</td>\n</tr>\n<tr>\n<td>pclass</td>\n<td>Ticket class</td>\n<td>1 = 1st, 2 = 2nd, 3 = 3rd</td>\n</tr>\n<tr>\n<td>sex</td>\n<td>Sex</td>\n<td></td>\n</tr>\n<tr>\n<td>Age</td>\n<td>Age in years</td>\n<td></td>\n</tr>\n<tr>\n<td>sibsp</td>\n<td># of siblings / spouses aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>parch</td>\n<td># of parents / children aboard the Titanic</td>\n<td></td>\n</tr>\n<tr>\n<td>ticket</td>\n<td>Ticket number</td>\n<td></td>\n</tr>\n<tr>\n<td>fare</td>\n<td>Passenger fare</td>\n<td></td>\n</tr>\n<tr>\n<td>cabin</td>\n<td>Cabin number</td>\n<td></td>\n</tr>\n<tr>\n<td>embarked</td>\n<td>Port of Embarkation</td>\n<td>C = Cherbourg, Q = Queenstown, S = Southampton</td>\n</tr>\n</tbody>\n</table>\n","metadata":{}},{"cell_type":"markdown","source":"#### Data Pre-Processing: \n","metadata":{}},{"cell_type":"markdown","source":"Let’s load the dataset.  \n","metadata":{}},{"cell_type":"code","source":"await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/titanic.csv\", overwrite=True)\n\ndf = pd.read_csv(\"titanic.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.667149Z","iopub.status.idle":"2025-07-15T18:17:56.667729Z","shell.execute_reply.started":"2025-07-15T18:17:56.667471Z","shell.execute_reply":"2025-07-15T18:17:56.667494Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can drop the following columns <code>'Name','Ticket','Cabin','PassengerId','Embarked' </code> for simplicity.\n","metadata":{}},{"cell_type":"code","source":"df=df.drop(columns=['Name','Ticket','Cabin','PassengerId','Embarked'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.669955Z","iopub.status.idle":"2025-07-15T18:17:56.670434Z","shell.execute_reply.started":"2025-07-15T18:17:56.670188Z","shell.execute_reply":"2025-07-15T18:17:56.670209Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We will assign \"0\" to \"female\" sex, and \"1\" to \"male\" sex, known as feature binarization. \n","metadata":{}},{"cell_type":"code","source":"df.loc[df['Sex']!='male','Sex']=0\ndf.loc[df['Sex']=='male','Sex']=1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.672715Z","iopub.status.idle":"2025-07-15T18:17:56.673158Z","shell.execute_reply.started":"2025-07-15T18:17:56.672917Z","shell.execute_reply":"2025-07-15T18:17:56.672932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.674855Z","iopub.status.idle":"2025-07-15T18:17:56.675615Z","shell.execute_reply.started":"2025-07-15T18:17:56.675159Z","shell.execute_reply":"2025-07-15T18:17:56.675181Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We will check for missing values.   \n","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.677411Z","iopub.status.idle":"2025-07-15T18:17:56.677853Z","shell.execute_reply.started":"2025-07-15T18:17:56.677656Z","shell.execute_reply":"2025-07-15T18:17:56.677677Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Here, we replace the  missing values in age, with the average age.\n","metadata":{}},{"cell_type":"code","source":"df['Age'].fillna(df['Age'].mean(),inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.679538Z","iopub.status.idle":"2025-07-15T18:17:56.679979Z","shell.execute_reply.started":"2025-07-15T18:17:56.679795Z","shell.execute_reply":"2025-07-15T18:17:56.679820Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We will assign the dataframe to X, for clustering, and drop our target, the <code>Survival</code>  column. \n","metadata":{}},{"cell_type":"code","source":"X=df.drop(columns=['Survived'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.681311Z","iopub.status.idle":"2025-07-15T18:17:56.681770Z","shell.execute_reply.started":"2025-07-15T18:17:56.681560Z","shell.execute_reply":"2025-07-15T18:17:56.681580Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, we will standardize the data  <code>X</code>:\n","metadata":{}},{"cell_type":"code","source":"X=df.apply(lambda x: (x-x.mean())/(x.std()+0.0000001), axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.683454Z","iopub.status.idle":"2025-07-15T18:17:56.683939Z","shell.execute_reply.started":"2025-07-15T18:17:56.683718Z","shell.execute_reply":"2025-07-15T18:17:56.683738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.685445Z","iopub.status.idle":"2025-07-15T18:17:56.685913Z","shell.execute_reply.started":"2025-07-15T18:17:56.685694Z","shell.execute_reply":"2025-07-15T18:17:56.685714Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Apply the mean-shift to Titanic data frame X:\n","metadata":{}},{"cell_type":"markdown","source":"To apply the mean-shift algorithm to X, first use the <code>estimate_bandwidth</code> function to estimate the value for the bandwidth parameter. Then create a MeanShift object and fit it to X:\n","metadata":{}},{"cell_type":"code","source":"# TO DO\nbandwidth = estimate_bandwidth(X)\nms = MeanShift(bandwidth=bandwidth , bin_seeding=True)\nms.fit(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.688411Z","iopub.status.idle":"2025-07-15T18:17:56.688856Z","shell.execute_reply.started":"2025-07-15T18:17:56.688628Z","shell.execute_reply":"2025-07-15T18:17:56.688648Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Next, we append the clusters to the dataset for analysis. \n","metadata":{}},{"cell_type":"code","source":"X['cluster']=ms.labels_\ndf['cluster']=ms.labels_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.690361Z","iopub.status.idle":"2025-07-15T18:17:56.690732Z","shell.execute_reply.started":"2025-07-15T18:17:56.690587Z","shell.execute_reply":"2025-07-15T18:17:56.690601Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, we group by clusters, to see that certain clusters have a larger chance of survival. \n","metadata":{}},{"cell_type":"code","source":"df.groupby('cluster').mean().sort_values(by=['Survived'], ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.693027Z","iopub.status.idle":"2025-07-15T18:17:56.693375Z","shell.execute_reply.started":"2025-07-15T18:17:56.693209Z","shell.execute_reply":"2025-07-15T18:17:56.693221Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"From the table above, we see that there are 7 clusters generated by the mean-shift analysis, each cluster contains the average percentage of survivors. \n\nFor instance, cluster 5, has 100 % of survivors, with the average age of 35.3, passengers belonging to the 1st class, and the passengers who paid the highest fare, 512.33 per ticket. Interestingly, Cluster 6, has 0 % of survivors, with the average age of 61, also belonging to the 1st class and in the mid-range ticket fare. It is not surprising that the highest odds for survival were held by the younger and richer groups of passengers.\n","metadata":{}},{"cell_type":"markdown","source":"<h2 id=\"E_1\">How Mean Shift Works (Optional) </h2> \n","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Mean Shift algorithm starts by placing a circle centered on each instance; then for each circle it computes the mean of all the instances located within it, and it shifts the circle so that it is centered on the mean. Next, it iterates this mean-shifting step until all the circles stop moving (i.e., until each of them is centered on the mean of the instances it contains). Mean Shift shifts the circles in the direction of higher density, until each of them has found a local density maximum. Finally, all the instances whose circles have settled in the same place (or close enough) are assigned to the same cluster. \n\nIn the following section, we will review Kernel Density Estimation, then we will derive the Mean Shift vector, and show how it finds the maximum values of the distribution. This section is optional and you can skip it and go to the next sections, where we apply the Mean Shift algorithm to the real data. \n","metadata":{}},{"cell_type":"markdown","source":"<h3>Kernel Density Estimation </h3>\n","metadata":{}},{"cell_type":"markdown","source":"Let's say we have $\\{\\boldsymbol{x}_{1},..,\\boldsymbol{x}_{n}\\}$ D  dimensional samples, it can be  difficult to calculate   the histogram for density estimation, but we can represent the density using  Kernel Density Estimation (KDE). The Kernel is a Function of $\\boldsymbol{x}$ and the sample $\\boldsymbol{x}_i$, for example, the  Gaussian kernel of the  $i-th$ sample is given by:\n","metadata":{}},{"cell_type":"markdown","source":" $K_{h}(\\boldsymbol{x}-\\boldsymbol{x}_{i})={\\frac {1}{{\\sqrt {2\\pi h }^D} }}e^{-{\\frac {|\\boldsymbol{x}-\\boldsymbol{x}_{i}|^{2}}{2h^{2}}}}$\n","metadata":{}},{"cell_type":"markdown","source":"$h$ is a bandwidth parameter and it is a free parameter, we can code the kernel in Python as a function of the distance  $|\\boldsymbol{x}-\\boldsymbol{x}_{i}|^{2}$ and $h$ :\n","metadata":{}},{"cell_type":"code","source":"def gaussian(d, h):\n    return np.exp(-0.5*((d/h))**2) / (h*math.sqrt(2*math.pi))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.694833Z","iopub.status.idle":"2025-07-15T18:17:56.695238Z","shell.execute_reply.started":"2025-07-15T18:17:56.695052Z","shell.execute_reply":"2025-07-15T18:17:56.695072Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"There are many types of kernels, we chose the Gaussian Kernel for simplicity.\n","metadata":{}},{"cell_type":"markdown","source":"We can calculate the Kernel  function  for $x_1=1$, which we will refer to as sample <code>s</code>, $x$ will be in the range between $-2<x<4$. \nWe will try it for $h=1$ and $h=3$.\n","metadata":{}},{"cell_type":"code","source":"s=1 # a sample point\n\nx = np.linspace(-2, 4, num=200)\ndist=np.sqrt(((x-s)**2))\nkernel_1=gaussian(dist, 1)\nkernel_2=gaussian(dist, 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.696547Z","iopub.status.idle":"2025-07-15T18:17:56.696966Z","shell.execute_reply.started":"2025-07-15T18:17:56.696760Z","shell.execute_reply":"2025-07-15T18:17:56.696780Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can plot the kernel functions for the different values of $h$ , and overlay the histogram, which is zero everywhere, except where the data point exists:\n","metadata":{}},{"cell_type":"code","source":"plt.plot(x,kernel_1,label='h=1')\nplt.plot(x,kernel_2,label='h=3')\nplt.plot(s,0,'x',label=\"$x_{1}$=1\")\nplt.hist(s, 10, facecolor='blue', alpha=0.5,label=\"Histogram\")\nplt.xlabel('x')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.698394Z","iopub.status.idle":"2025-07-15T18:17:56.698867Z","shell.execute_reply.started":"2025-07-15T18:17:56.698659Z","shell.execute_reply":"2025-07-15T18:17:56.698679Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We see that for x close to our sample point ($x_{1}$ = 1), the gaussian kernel function returns larger values; for x far away from $x_{1}$, the kernel function gives smaller values that are approaching 0.\n","metadata":{}},{"cell_type":"markdown","source":"For many samples the  KDE is given by:\n","metadata":{}},{"cell_type":"markdown","source":" ${\\hat {f}}_{h}(x)={\\frac {1}{n h^{D}}}\\sum _{i=1}^{n}K_{h}(\\boldsymbol{x}-\\boldsymbol{x}_{i})$\n","metadata":{}},{"cell_type":"markdown","source":"In Python, we generate the KDE with bandwith $h$ for set of point $x_i$, stored in the NumPy array <code>S</code>, in the range of $x$ as follows:\n","metadata":{}},{"cell_type":"code","source":"def kernel_density(S,x,h=1):\n\n    density=np.zeros((200))\n    for s in S:\n        #Determine the distance and kernel for each point \n        dist=np.sqrt(((x-s)**2))\n        kernel=gaussian(dist, h)\n        #Find the sum  \n        density+=kernel\n    #Normalize the sum  \n    density=density/density.sum() \n    \n    return density","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.700706Z","iopub.status.idle":"2025-07-15T18:17:56.701251Z","shell.execute_reply.started":"2025-07-15T18:17:56.700999Z","shell.execute_reply":"2025-07-15T18:17:56.701024Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Consider the following data points:  \n","metadata":{}},{"cell_type":"code","source":"S=np.zeros((200))\nS[0:100] = np.random.normal(-10, 1, 100)\nS[100:200]=np.random.normal(10, 1, 100)\nplt.plot(S,np.zeros((200)),'x')\nplt.xlabel(\"$x_{i}$\")\nplt.show()","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.702434Z","iopub.status.idle":"2025-07-15T18:17:56.702771Z","shell.execute_reply.started":"2025-07-15T18:17:56.702632Z","shell.execute_reply":"2025-07-15T18:17:56.702649Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can generate the density in a specified region $x$.\n","metadata":{}},{"cell_type":"code","source":"x = np.linspace(S.min()-3, S.max()+3, num=200)\ndensity=kernel_density(S,x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.703678Z","iopub.status.idle":"2025-07-15T18:17:56.703952Z","shell.execute_reply.started":"2025-07-15T18:17:56.703827Z","shell.execute_reply":"2025-07-15T18:17:56.703838Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can plot the results along with clusters locations. They should correspond to the two peaks of the distribution.   \n","metadata":{}},{"cell_type":"code","source":"plt.plot(x,density,label=\" KDE\")\nplt.plot(S,np.zeros((200,1)),'x',label=\"$x_{i}$\")\nplt.xlabel('x')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.705434Z","iopub.status.idle":"2025-07-15T18:17:56.705707Z","shell.execute_reply.started":"2025-07-15T18:17:56.705586Z","shell.execute_reply":"2025-07-15T18:17:56.705597Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To find the two maximums we can apply the Gradient Ascent to each vector  $\\{\\boldsymbol{x}_{1},..,\\boldsymbol{x}_{n}\\}$:\n","metadata":{}},{"cell_type":"markdown","source":"$ \\boldsymbol{\\hat{x}}^{k+1}_i := \\boldsymbol{\\hat{x}}^{k}_i + \\eta \\nabla {\\hat {f}}_{h}(\\boldsymbol{\\hat{x}}^{k}_i) $\n","metadata":{}},{"cell_type":"markdown","source":"For example, we set for $\\boldsymbol{\\hat{x}}^{0}_{1}=\\boldsymbol{x}_1$, then apply:\n","metadata":{}},{"cell_type":"markdown","source":"$ \\boldsymbol{\\hat{x}}^{k+1}_1 := \\boldsymbol{\\hat{x}}^{k}_1 + \\eta \\nabla {\\hat {f}}_{h}(\\boldsymbol{\\hat{x}}^{k}_1) $\n","metadata":{}},{"cell_type":"markdown","source":" for $\\boldsymbol{\\hat{x}}^{0}_{2}=\\boldsymbol{x}_2$, then apply:\n","metadata":{}},{"cell_type":"markdown","source":"$ \\boldsymbol{\\hat{x}}^{k+1}_2 := \\boldsymbol{\\hat{x}}^{k}_2 + \\eta \\nabla {\\hat {f}}_{h}(\\boldsymbol{\\hat{x}}^{k}_2) $\n","metadata":{}},{"cell_type":"markdown","source":"Mean Shift is an alternative method for selecting a good value for $\\eta$ and $h$ , so that each $ \\boldsymbol{\\hat{x}}^{k+1}_i$ should approach the two maximums.\n","metadata":{}},{"cell_type":"markdown","source":"<h3>Mean Shift From Scratch  </h3>\n","metadata":{}},{"cell_type":"markdown","source":"In order to find the peak of the distribution, we calculate the gradient. The mean shift vector is proportional to the gradient and always points toward the direction of the maximum increase in density. The expression for the mean shift is shown here along with the Python code: \n","metadata":{}},{"cell_type":"markdown","source":" $\\nabla  {\\hat {f}}_{h}(\\boldsymbol{x}) \\varpropto\\ \\boldsymbol{m}_h(\\boldsymbol{x})=\\frac{ \\sum_{i} K'(\\boldsymbol{x}_i - \\boldsymbol{x}) \\boldsymbol{x}_i } {\\sum_{i} K'(\\boldsymbol{x}_i - \\boldsymbol{x})}-\\boldsymbol{x} $\n","metadata":{}},{"cell_type":"markdown","source":" where $K'$ is the derivative of the kernel,  we can output the mean shift values for <code>S</code> as follows:\n","metadata":{}},{"cell_type":"code","source":"mean_shift=((density.reshape(-1,1)*S).sum(0) / density.sum())-x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.707476Z","iopub.status.idle":"2025-07-15T18:17:56.707754Z","shell.execute_reply.started":"2025-07-15T18:17:56.707633Z","shell.execute_reply":"2025-07-15T18:17:56.707644Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If we overlay the mean shift value over the distribution, $\\boldsymbol{m}_h(\\boldsymbol{x})$, we will see that vectors point towards the two peaks.\n","metadata":{}},{"cell_type":"code","source":"plt.plot(x,density,label=\" KDE\")\nplt.plot(S,np.zeros((200,1)),'x',label=\"$x_{i}$\")\nplt.quiver(x, np.zeros((200,1)),mean_shift, np.zeros((200,1)), units='width',label=\"$m_{h}(x)$\")\nplt.xlabel('x')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.709112Z","iopub.status.idle":"2025-07-15T18:17:56.709534Z","shell.execute_reply.started":"2025-07-15T18:17:56.709309Z","shell.execute_reply":"2025-07-15T18:17:56.709328Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"By plugging in the value of  the mean shift vector into the expression  for gradient ascent, we get:\n","metadata":{}},{"cell_type":"markdown","source":"$ \\boldsymbol{\\hat{x}}^{k+1}_i := \\boldsymbol{\\hat{x}}^{k}_i + \\eta \\nabla {\\hat {f}}_{h}(\\boldsymbol{\\hat{x}}^{k}_i) \\approx\\boldsymbol{x}^{k}_i +  \\boldsymbol{m}_h(\\boldsymbol{\\hat{x}}^{k}_i)$\n","metadata":{}},{"cell_type":"markdown","source":"$ \\boldsymbol{\\hat{x}}^{k+1}_i := \\boldsymbol{\\hat{x}}^{k}_i +\\frac{ \\sum_{i} K(\\boldsymbol{x}_i -\\boldsymbol{\\hat{x}}^{k}_i) \\boldsymbol{x}_i } {\\sum_{i} K(\\boldsymbol{x}_i - \\boldsymbol{\\hat{x}}^{k}_i)}-\\boldsymbol{\\hat{x}}^{k}_i$\n","metadata":{}},{"cell_type":"markdown","source":"$ \\boldsymbol{\\hat{x}}^{k+1}_i := \\frac{ \\sum_{i} K(\\boldsymbol{x}_i -\\boldsymbol{\\hat{x}}^{k}_i) \\boldsymbol{x}_i } {\\sum_{i} K(\\boldsymbol{x}_i - \\boldsymbol{\\hat{x}}^{k}_i)}$\n","metadata":{}},{"cell_type":"markdown","source":"We can run the algorithm  for three iterations, each point should converge to the cluster centers :\n","metadata":{}},{"cell_type":"code","source":"Xhat=np.copy(S.reshape(-1,1))\nS_=S.reshape(-1,1)\n\n\nfor k in range(3):\n    plt.plot(x,density,label=\" KDE\")\n    plt.plot(Xhat,np.zeros((200,1)),'x',label=\"$\\hat{x}^{k}_i$,k=\"+str(k))\n    plt.xlabel('x')\n    plt.legend()\n    plt.show()\n  \n    for i,xhat in enumerate(Xhat):\n        dist=np.sqrt(((xhat-S_)**2).sum(1))\n        weight = gaussian(dist, 2.5)\n        Xhat[i] = (weight.reshape(-1,1)*S_).sum(0) / weight.sum()\n    ","metadata":{"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.710492Z","iopub.status.idle":"2025-07-15T18:17:56.710944Z","shell.execute_reply.started":"2025-07-15T18:17:56.710715Z","shell.execute_reply":"2025-07-15T18:17:56.710735Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In practice, we will drop many of the data points, as they get closer together. Here is a quick way. \n","metadata":{}},{"cell_type":"code","source":"np.unique(Xhat.astype(int))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T18:17:56.712378Z","iopub.status.idle":"2025-07-15T18:17:56.712747Z","shell.execute_reply.started":"2025-07-15T18:17:56.712608Z","shell.execute_reply":"2025-07-15T18:17:56.712622Z"}},"outputs":[],"execution_count":null}]}