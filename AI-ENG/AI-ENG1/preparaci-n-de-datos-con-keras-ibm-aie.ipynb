{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://cognitiveclass.ai/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"400\"> </a>\n\n<h1 align=center><font size = 5>Data Preparation</font></h1>\n","metadata":{}},{"cell_type":"markdown","source":"## Objective\n","metadata":{}},{"cell_type":"markdown","source":"In this lab, you will learn how to load images and manipulate them for training using Keras ImageDataGenerator.\n","metadata":{}},{"cell_type":"markdown","source":"## Table of Contents\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n\n<font size = 3>    \n\n1. <a href=\"#item22\">Import Libraries and Packages</a> \n2. <a href=\"#item21\">Download Data</a> \n3. <a href=\"#item23\">Construct an ImageDataGenerator Instance</a>  \n4. <a href=\"#item24\">Visualize Batches of Images</a>\n5. <a href=\"#item25\">Questions</a>    \n</font>\n    \n</div>\n","metadata":{}},{"cell_type":"markdown","source":"   \n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"item1\"></a>\n","metadata":{}},{"cell_type":"markdown","source":"<a id='item21'></a>\n","metadata":{}},{"cell_type":"markdown","source":"## Import Libraries and Packages\n","metadata":{}},{"cell_type":"markdown","source":"Before we proceed, let's import the libraries and packages that we will need to complete the rest of this lab.\n","metadata":{}},{"cell_type":"code","source":"!pip install skillsnetwork\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport skillsnetwork\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:52:34.976756Z","iopub.execute_input":"2025-06-04T17:52:34.977067Z","iopub.status.idle":"2025-06-04T17:52:58.271560Z","shell.execute_reply.started":"2025-06-04T17:52:34.977041Z","shell.execute_reply":"2025-06-04T17:52:58.270363Z"}},"outputs":[{"name":"stdout","text":"Collecting skillsnetwork\n  Downloading skillsnetwork-0.21.10-py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from skillsnetwork) (7.34.0)\nCollecting ipywidgets<=8.1.3 (from skillsnetwork)\n  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from skillsnetwork) (2.32.3)\nRequirement already satisfied: tqdm<5,>=4 in /usr/local/lib/python3.11/dist-packages (from skillsnetwork) (4.67.1)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<=8.1.3->skillsnetwork) (0.2.2)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<=8.1.3->skillsnetwork) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.11 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<=8.1.3->skillsnetwork) (4.0.14)\nRequirement already satisfied: jupyterlab-widgets~=3.0.11 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<=8.1.3->skillsnetwork) (3.0.13)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->skillsnetwork) (75.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->skillsnetwork) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->skillsnetwork) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->skillsnetwork) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->skillsnetwork) (3.0.50)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->skillsnetwork) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->skillsnetwork) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->skillsnetwork) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->skillsnetwork) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->skillsnetwork) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->skillsnetwork) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->skillsnetwork) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->skillsnetwork) (2025.4.26)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->skillsnetwork) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->skillsnetwork) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->skillsnetwork) (0.2.13)\nDownloading skillsnetwork-0.21.10-py3-none-any.whl (26 kB)\nDownloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: ipywidgets, skillsnetwork\n  Attempting uninstall: ipywidgets\n    Found existing installation: ipywidgets 8.1.5\n    Uninstalling ipywidgets-8.1.5:\n      Successfully uninstalled ipywidgets-8.1.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ipywidgets-8.1.3 skillsnetwork-0.21.10\n","output_type":"stream"},{"name":"stderr","text":"2025-06-04 17:52:42.641007: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749059562.872789      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749059562.942754      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2909036595.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskillsnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.11/dist-packages/keras/api/preprocessing/image/__init__.py)"],"ename":"ImportError","evalue":"cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (/usr/local/lib/python3.11/dist-packages/keras/api/preprocessing/image/__init__.py)","output_type":"error"}],"execution_count":1},{"cell_type":"markdown","source":"## Download Data\n","metadata":{}},{"cell_type":"markdown","source":"For your convenience, I have placed the data on a server which you can retrieve and unzip easily using the **skillsnetwork.prepare** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed.\n","metadata":{}},{"cell_type":"code","source":"await skillsnetwork.prepare(\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week2.zip\",path = \"./\", overwrite=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:55:12.071981Z","iopub.execute_input":"2025-06-04T17:55:12.072343Z","iopub.status.idle":"2025-06-04T17:55:41.777041Z","shell.execute_reply.started":"2025-06-04T17:55:12.072314Z","shell.execute_reply":"2025-06-04T17:55:41.776027Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading concrete_data_week2.zip:   0%|          | 0/260502910 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa672b498bad4451bf09adda647683b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/80011 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"623f922b6fc54aeea3c70484535edfd0"}},"metadata":{}},{"name":"stdout","text":"Saved to '.'\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"Now, you should see two folders appear in the left pane: *Positive* and *Negative*. *Negative* is the negative class like we defined it earlier and it represents the concrete images with no cracks. *Positive* on the other hand is the positive class and represents the concrete images with cracks.\n","metadata":{}},{"cell_type":"markdown","source":"**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *Negative* and *Positive* folders. This may consume all of your memory and you may end up with a **50*** error. So please **DO NOT DO IT**.\n","metadata":{}},{"cell_type":"markdown","source":"You can check the content of <code>./concrete_data_week2</code> by running the following:\n","metadata":{}},{"cell_type":"code","source":"!ls ./concrete_data_week2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:56:36.266439Z","iopub.execute_input":"2025-06-04T17:56:36.266788Z","iopub.status.idle":"2025-06-04T17:56:36.405111Z","shell.execute_reply.started":"2025-06-04T17:56:36.266761Z","shell.execute_reply":"2025-06-04T17:56:36.403989Z"}},"outputs":[{"name":"stdout","text":"Negative  Positive\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"or the following:\n","metadata":{}},{"cell_type":"code","source":"os.listdir('concrete_data_week2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:56:39.762284Z","iopub.execute_input":"2025-06-04T17:56:39.763195Z","iopub.status.idle":"2025-06-04T17:56:39.769877Z","shell.execute_reply.started":"2025-06-04T17:56:39.763142Z","shell.execute_reply":"2025-06-04T17:56:39.769085Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['Positive', 'Negative', '.DS_Store']"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"<a id='item22'></a>\n","metadata":{}},{"cell_type":"markdown","source":" \n","metadata":{}},{"cell_type":"markdown","source":"<a id='item23'></a>\n","metadata":{}},{"cell_type":"markdown","source":"## Construct an ImageDataGenerator Instance\n","metadata":{}},{"cell_type":"markdown","source":"In this section, you will learn how to define a Keras ImageDataGenerator instance and use it to load and manipulate data for building a deep learning model.\n","metadata":{}},{"cell_type":"markdown","source":"Before we proceed, let's define a variable that represents the path to the folder containing our data which is <code>concrete_data_week2</code> in this case.\n","metadata":{}},{"cell_type":"code","source":"dataset_dir = './concrete_data_week2'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:56:44.314856Z","iopub.execute_input":"2025-06-04T17:56:44.315153Z","iopub.status.idle":"2025-06-04T17:56:44.319516Z","shell.execute_reply.started":"2025-06-04T17:56:44.315132Z","shell.execute_reply":"2025-06-04T17:56:44.318606Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Keras ImageDataGenerator requires images be arranged in a certain folder hierarchy, where the main directory would contain folders equal to the number of classes in your problem. Since in this case we are trying to build a classifier of two classes, then our main directory, which is <code>concrete_data_week2</code>, should contain two folders, one for each class. This has already been done for you as the negative images are in one folder and the positive images are in another folder.\n","metadata":{}},{"cell_type":"markdown","source":"Let's go ahead and define an instance of the Keras ImageDataGenerator. \n","metadata":{}},{"cell_type":"markdown","source":"#### Standard ImageDataGenerator\n","metadata":{}},{"cell_type":"markdown","source":"You can define a standard one like this, where you are simply using the ImageDataGenerator to train your model in batches.\n","metadata":{}},{"cell_type":"code","source":"# instantiate your image data generator\n# Celda 1: importar ImageDataGenerator desde tensorflow.keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndata_generator = ImageDataGenerator()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T17:58:43.505627Z","iopub.execute_input":"2025-06-04T17:58:43.505981Z","iopub.status.idle":"2025-06-04T17:58:43.631664Z","shell.execute_reply.started":"2025-06-04T17:58:43.505955Z","shell.execute_reply":"2025-06-04T17:58:43.630760Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Next, you use the <code>flow_from_directory</code> methods to loop through the images in batches. In this method, you pass the directory where the images reside, the size of each batch, *batch_size*, and since batches are sampled randomly, then you can also specify a random seed, *seed*, if you would like to reproduce the batch sampling. In case you would like to resize your images, then you can using the *target_size* argument to accomplish that.\n","metadata":{}},{"cell_type":"code","source":"image_generator = data_generator.flow_from_directory(\n    dataset_dir,\n    batch_size=4,\n    class_mode='categorical',\n    seed=24\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T18:10:12.962885Z","iopub.execute_input":"2025-06-04T18:10:12.963250Z","iopub.status.idle":"2025-06-04T18:10:14.082231Z","shell.execute_reply.started":"2025-06-04T18:10:12.963226Z","shell.execute_reply":"2025-06-04T18:10:14.080829Z"}},"outputs":[{"name":"stdout","text":"Found 40000 images belonging to 2 classes.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1271559352.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     )\n\u001b[1;32m      7\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'batch_num' is not defined"],"ename":"NameError","evalue":"name 'batch_num' is not defined","output_type":"error"}],"execution_count":29},{"cell_type":"markdown","source":"What is great about this method, is it prints a summary of it found in the directory passed. Here, it found 40,000 images in total belonging to 2 classes.\n","metadata":{}},{"cell_type":"markdown","source":"Now, to access the batches, you use the <code>next</code> method as follows:\n","metadata":{}},{"cell_type":"code","source":"# 3) Obtener el primer batch usando next(...)\nfirst_batch = next(image_generator)\n# first_batch es una tupla: (array_de_imágenes, array_de_labels_one_hot)\nprint(type(first_batch), len(first_batch))  # debería mostrar: <class 'tuple'> 2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T18:00:53.279028Z","iopub.execute_input":"2025-06-04T18:00:53.279392Z","iopub.status.idle":"2025-06-04T18:00:53.347611Z","shell.execute_reply.started":"2025-06-04T18:00:53.279368Z","shell.execute_reply":"2025-06-04T18:00:53.346774Z"}},"outputs":[{"name":"stdout","text":"<class 'tuple'> 2\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"As you can see, this returned the images along with their labels. Therefore, the following returns the images only,\n","metadata":{}},{"cell_type":"code","source":"# Usando __getitem__ implícito (equivalente a first_batch = image_generator[0])\nfirst_batch = image_generator[0]\nfirst_batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T18:01:03.301924Z","iopub.execute_input":"2025-06-04T18:01:03.302253Z","iopub.status.idle":"2025-06-04T18:01:03.318227Z","shell.execute_reply.started":"2025-06-04T18:01:03.302232Z","shell.execute_reply":"2025-06-04T18:01:03.317265Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(array([[[[151., 149., 150.],\n          [153., 151., 152.],\n          [155., 153., 154.],\n          ...,\n          [153., 149., 148.],\n          [153., 149., 148.],\n          [153., 149., 148.]],\n \n         [[152., 150., 151.],\n          [154., 152., 153.],\n          [156., 154., 155.],\n          ...,\n          [154., 150., 149.],\n          [154., 150., 149.],\n          [154., 150., 149.]],\n \n         [[153., 151., 152.],\n          [155., 153., 154.],\n          [156., 154., 155.],\n          ...,\n          [156., 152., 151.],\n          [156., 152., 151.],\n          [156., 152., 151.]],\n \n         ...,\n \n         [[142., 140., 143.],\n          [142., 140., 143.],\n          [142., 140., 143.],\n          ...,\n          [139., 135., 136.],\n          [142., 138., 139.],\n          [145., 141., 142.]],\n \n         [[142., 140., 143.],\n          [142., 140., 143.],\n          [142., 140., 143.],\n          ...,\n          [140., 136., 137.],\n          [142., 138., 139.],\n          [146., 142., 143.]],\n \n         [[142., 140., 143.],\n          [142., 140., 143.],\n          [142., 140., 143.],\n          ...,\n          [141., 137., 138.],\n          [144., 140., 141.],\n          [147., 143., 144.]]],\n \n \n        [[[189., 186., 181.],\n          [191., 188., 183.],\n          [194., 191., 186.],\n          ...,\n          [186., 185., 181.],\n          [184., 183., 179.],\n          [183., 182., 178.]],\n \n         [[188., 185., 180.],\n          [190., 187., 182.],\n          [194., 191., 186.],\n          ...,\n          [186., 185., 181.],\n          [185., 184., 180.],\n          [184., 183., 179.]],\n \n         [[186., 183., 178.],\n          [189., 186., 181.],\n          [193., 190., 185.],\n          ...,\n          [186., 185., 181.],\n          [185., 184., 180.],\n          [185., 184., 180.]],\n \n         ...,\n \n         [[188., 185., 180.],\n          [187., 184., 179.],\n          [186., 183., 178.],\n          ...,\n          [170., 170., 162.],\n          [170., 170., 162.],\n          [171., 171., 163.]],\n \n         [[188., 185., 180.],\n          [187., 184., 179.],\n          [186., 183., 178.],\n          ...,\n          [173., 170., 163.],\n          [171., 171., 163.],\n          [172., 172., 164.]],\n \n         [[188., 185., 180.],\n          [187., 184., 179.],\n          [186., 183., 178.],\n          ...,\n          [181., 178., 171.],\n          [179., 179., 171.],\n          [179., 179., 171.]]],\n \n \n        [[[181., 173., 162.],\n          [176., 168., 157.],\n          [168., 160., 149.],\n          ...,\n          [171., 167., 156.],\n          [170., 166., 155.],\n          [169., 165., 154.]],\n \n         [[180., 172., 161.],\n          [176., 168., 157.],\n          [170., 162., 151.],\n          ...,\n          [172., 168., 157.],\n          [171., 167., 156.],\n          [170., 166., 155.]],\n \n         [[179., 171., 160.],\n          [176., 168., 157.],\n          [171., 163., 152.],\n          ...,\n          [174., 170., 159.],\n          [173., 169., 158.],\n          [172., 168., 157.]],\n \n         ...,\n \n         [[175., 171., 160.],\n          [178., 174., 163.],\n          [182., 178., 167.],\n          ...,\n          [173., 169., 160.],\n          [173., 169., 160.],\n          [173., 168., 162.]],\n \n         [[175., 171., 160.],\n          [178., 174., 163.],\n          [182., 178., 167.],\n          ...,\n          [175., 170., 164.],\n          [175., 170., 164.],\n          [175., 170., 164.]],\n \n         [[175., 171., 160.],\n          [178., 174., 163.],\n          [182., 178., 167.],\n          ...,\n          [177., 172., 166.],\n          [177., 172., 166.],\n          [177., 172., 166.]]],\n \n \n        [[[150., 149., 147.],\n          [148., 147., 145.],\n          [146., 145., 143.],\n          ...,\n          [199., 195., 192.],\n          [194., 190., 187.],\n          [189., 185., 182.]],\n \n         [[153., 152., 150.],\n          [152., 151., 149.],\n          [151., 150., 148.],\n          ...,\n          [196., 192., 189.],\n          [192., 188., 185.],\n          [186., 182., 179.]],\n \n         [[153., 152., 150.],\n          [155., 154., 152.],\n          [156., 155., 153.],\n          ...,\n          [192., 188., 185.],\n          [188., 184., 181.],\n          [182., 178., 175.]],\n \n         ...,\n \n         [[179., 175., 174.],\n          [180., 176., 175.],\n          [181., 177., 176.],\n          ...,\n          [174., 170., 167.],\n          [173., 169., 166.],\n          [173., 169., 166.]],\n \n         [[180., 176., 175.],\n          [180., 176., 175.],\n          [180., 176., 175.],\n          ...,\n          [176., 172., 169.],\n          [175., 171., 168.],\n          [173., 169., 166.]],\n \n         [[182., 178., 177.],\n          [181., 177., 176.],\n          [179., 175., 174.],\n          ...,\n          [180., 176., 173.],\n          [177., 173., 170.],\n          [174., 170., 167.]]]], dtype=float32),\n array([[1., 0.],\n        [0., 1.],\n        [1., 0.],\n        [0., 1.]], dtype=float32))"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"and the following returns the labels only.\n","metadata":{}},{"cell_type":"code","source":"# Celda 3: obtener el primer batch y extraer solo las etiquetas\nfirst_batch_labels = next(image_generator)[1]\nprint(first_batch_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T18:02:12.677499Z","iopub.execute_input":"2025-06-04T18:02:12.678239Z","iopub.status.idle":"2025-06-04T18:02:12.689545Z","shell.execute_reply.started":"2025-06-04T18:02:12.678208Z","shell.execute_reply":"2025-06-04T18:02:12.688564Z"}},"outputs":[{"name":"stdout","text":"[[0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"#### Custom ImageDataGenerator\n","metadata":{}},{"cell_type":"markdown","source":"You can also specify some transforms, like scaling, rotations, and flips, that you would like applied to the images when you define an ImageDataGenerator object. Say you want to normalize your images, then you can define your ImageDataGenerator instance as follows:\n","metadata":{}},{"cell_type":"code","source":"# instantiate your image data generator\ndata_generator = ImageDataGenerator(\n    rescale=1./255\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T18:02:54.474950Z","iopub.execute_input":"2025-06-04T18:02:54.475294Z","iopub.status.idle":"2025-06-04T18:02:54.479490Z","shell.execute_reply.started":"2025-06-04T18:02:54.475270Z","shell.execute_reply":"2025-06-04T18:02:54.478667Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"And then you proceed with defining your *image_generator* using the *flow_from_directory* method, just like before.\n","metadata":{}},{"cell_type":"code","source":"image_generator = data_generator.flow_from_directory(\n    dataset_dir,\n    batch_size=4,\n    class_mode='categorical',\n    seed=24\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T18:02:58.950060Z","iopub.execute_input":"2025-06-04T18:02:58.950455Z","iopub.status.idle":"2025-06-04T18:03:00.108750Z","shell.execute_reply.started":"2025-06-04T18:02:58.950429Z","shell.execute_reply":"2025-06-04T18:03:00.107735Z"}},"outputs":[{"name":"stdout","text":"Found 40000 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"However, now we explore the first batch using the *next* method, \n","metadata":{}},{"cell_type":"code","source":"# Usando next()\nfirst_batch_labels = next(image_generator)[1]\nprint(first_batch_labels)\n\n# O bien con indexación\nfirst_batch_labels = image_generator[0][1]\nprint(first_batch_labels)\n\n# Asumiendo que ya creaste image_generator con flow_from_directory:\n# image_generator = ImageDataGenerator().flow_from_directory(...)\n\n# Opción A: usar next()\nfirst_batch = next(image_generator)\nprint(type(first_batch))       # Es una tupla (imágenes, etiquetas)\nprint(len(first_batch))        # Debe ser 2\n\n# Opción B: usar indexación\nfirst_batch = image_generator[0]\nprint(type(first_batch))\nprint(len(first_batch))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T18:05:09.029142Z","iopub.execute_input":"2025-06-04T18:05:09.029519Z","iopub.status.idle":"2025-06-04T18:05:09.058250Z","shell.execute_reply.started":"2025-06-04T18:05:09.029494Z","shell.execute_reply":"2025-06-04T18:05:09.057447Z"}},"outputs":[{"name":"stdout","text":"[[1. 0.]\n [0. 1.]\n [0. 1.]\n [0. 1.]]\n[[1. 0.]\n [0. 1.]\n [1. 0.]\n [0. 1.]]\n<class 'tuple'>\n2\n<class 'tuple'>\n2\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"we find that the values are not integer values anymore, but scaled resolution since the original number are divided by 255.\n","metadata":{}},{"cell_type":"markdown","source":"You can learn more about the Keras ImageDataGeneration class [here](https://keras.io/preprocessing/image/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01).\n","metadata":{}},{"cell_type":"markdown","source":"<a id='item24'></a>\n","metadata":{}},{"cell_type":"markdown","source":"## Visualize Batches of Images\n","metadata":{}},{"cell_type":"markdown","source":"Let write some code to visualize a batch. We will use subplots in order to make visualizing the images easier.\n","metadata":{}},{"cell_type":"markdown","source":"Recall that we can access our batch images as follows:\n\n<code>first_batch_images = image_generator.next()[0] # first batch</code>\n\n<code>second_batch_images = image_generator.next()[0] # second batch</code>\n\nand so on.\n","metadata":{}},{"cell_type":"code","source":"# --- Celda 2: invoca get_batch y dibuja el tercer batch ---\n\n# Ahora sí get_batch está definido, llamamos:\ngen3, third_batch = get_batch(batch_num=3, batch_size=4, seed=24)\nthird_images, third_labels = third_batch\n\n# Visualizamos las 4 imágenes en una grilla 2×2\nfig, axes = plt.subplots(2, 2, figsize=(6, 6))\naxes = axes.flatten()\nfor i, ax in enumerate(axes):\n    ax.imshow(third_images[i])\n    ax.axis(\"off\")\nplt.suptitle(\"Imágenes del tercer batch\", fontsize=14)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T18:10:49.165157Z","iopub.execute_input":"2025-06-04T18:10:49.165496Z","iopub.status.idle":"2025-06-04T18:10:49.187003Z","shell.execute_reply.started":"2025-06-04T18:10:49.165474Z","shell.execute_reply":"2025-06-04T18:10:49.185716Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/4277827772.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Ahora sí get_batch está definido, llamamos:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgen3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthird_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mthird_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthird_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthird_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'get_batch' is not defined"],"ename":"NameError","evalue":"name 'get_batch' is not defined","output_type":"error"}],"execution_count":30},{"cell_type":"markdown","source":"Remember that batches are sampled randomly from the data. In our first batch, we ended up with two negative image and two positive images.\n","metadata":{}},{"cell_type":"markdown","source":"**Important Note**: Because of a bug with the imshow function in Matplotlib, if you are plotting the unscaled RGB images, you have to cast the **image_data** to uint8 before you call the <code>imshow</code> function. So In the code above It looks like this:\n\nimage_data = first_batch_images[ind].astype(np.uint8)\n","metadata":{}},{"cell_type":"markdown","source":"<a id='item25'></a>\n","metadata":{}},{"cell_type":"markdown","source":"## Questions\n","metadata":{}},{"cell_type":"markdown","source":"### Question: Create a plot to visualize the images in the third batch.\n","metadata":{}},{"cell_type":"code","source":"## You can use this cell to type your code to answer the above question\n\n\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Question: How many images from each class are in the fourth batch?\n","metadata":{}},{"cell_type":"code","source":"## You can use this cell to type your code to answer the above question\n\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Question: Create a plot to visualize the second image in the fifth batch.\n","metadata":{}},{"cell_type":"code","source":"## You can use this cell to type your code to answer the above question\n\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Question: How many images from each class are in the fifth batch?\n","metadata":{}},{"cell_type":"code","source":"## You can use this cell to type your code to answer the above question\n\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"   \n","metadata":{}},{"cell_type":"markdown","source":"Make sure to answer the above questions as the quiz in this module is heavily based on them.\n","metadata":{}},{"cell_type":"markdown","source":"  \n","metadata":{}},{"cell_type":"markdown","source":"   \n","metadata":{}},{"cell_type":"markdown","source":"### Thank you for completing this lab!\n\nThis notebook was created by Alex Aklson. I hope you found this lab interesting and educational.\n","metadata":{}},{"cell_type":"markdown","source":"This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week2_LAB1).\n","metadata":{}},{"cell_type":"markdown","source":"\n## Change Log\n\n|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n|---|---|---|---|\n| 2020-09-18  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n\n","metadata":{}},{"cell_type":"markdown","source":"<hr>\n\nCopyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_medium=dswb&utm_source=bducopyrightlink&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01).\n","metadata":{}}]}