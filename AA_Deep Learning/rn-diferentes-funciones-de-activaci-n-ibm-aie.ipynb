{"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"422cf833aa8207dd98e8e8d27c87d81816d43276ee5b7b9f39c80705e0a7ef7d","kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Test Sigmoid, Tanh, and Relu Activations Functions on the MNIST Dataset</h1>\n","metadata":{}},{"cell_type":"markdown","source":"<h2>Objective</h2><ul><li> How to apply different activation functions on the MNIST dataset.</li></ul> \n","metadata":{}},{"cell_type":"markdown","source":"<h2>Table of Contents</h2>\n<p>In this lab, you will test sigmoid, tanh, and relu activation functions on the MNIST dataset.</p>\n\n<ul>\n    <li><a href=\"#Model\">Neural Network Module and Training Function</a></li>\n    <li><a href=\"#Makeup_Data\">Make Some Data</a></li>\n    <li><a href=\"#Train\">Define Several Neural Network, Criterion Function, and Optimizer</a></li>\n    <li><a href=\"#Test\">Test Sigmoid, Tanh, and Relu</a></li>\n    <li><a href=\"#Result\">Analyze Results</a></li>\n</ul>\n<p></p>\nEstimated Time Needed: <strong>25 min</strong>\n</div>\n\n<hr>\n","metadata":{}},{"cell_type":"markdown","source":"<h2>Preparation</h2>\n","metadata":{}},{"cell_type":"markdown","source":"We'll need the following libraries\n","metadata":{}},{"cell_type":"code","source":"# Uncomment the following line to install the torchvision library\n# !mamba install -y torchvision\n\n# Import the libraries we need for this lab\n\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\n\nimport matplotlib.pylab as plt\nimport numpy as np","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<h2 id=\"Model\">Neural Network Module and Training Function</h2> \n","metadata":{}},{"cell_type":"markdown","source":"Define the neural network module or class using the sigmoid activation function: \n","metadata":{}},{"cell_type":"code","source":"# Build the model with sigmoid function\n\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n    \n    # Prediction\n    def forward(self, x):\n        x = torch.sigmoid(self.linear1(x))  \n        x = self.linear2(x)\n        return x","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nDefine the neural network module or class using the Tanh activation function:\n","metadata":{}},{"cell_type":"code","source":"# Build the model with Tanh function\n\nclass NetTanh(nn.Module):\n\n    # Constructor\n    def __init__(self, D_in, H, D_out):\n        super(NetTanh, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n\n    # Prediction\n    def forward(self, x):\n        x = torch.tanh(self.linear1(x))\n        x = self.linear2(x)\n        return x","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define the neural network module or class using the Relu activation function:\n","metadata":{}},{"cell_type":"code","source":"# Build the model with Relu function\n\nclass NetRelu(nn.Module):\n\n    # Constructor\n    def __init__(self, D_in, H, D_out):\n        super(NetRelu, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n\n    # Prediction\n    def forward(self, x):\n        x = torch.relu(self.linear1(x))\n        x = self.linear2(x)\n        return x","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define a function to train the model. In this case, the function returns a Python dictionary to store the training loss for each iteration  and accuracy on the validation data.\n","metadata":{}},{"cell_type":"code","source":"# Define the function for training the model\n\ndef train(model, criterion, train_loader, validation_loader, optimizer, epochs = 100):\n    i = 0\n    useful_stuff = {'training_loss':[], 'validation_accuracy':[]}  \n\n    for epoch in range(epochs):\n        for i, (x, y) in enumerate(train_loader):\n            optimizer.zero_grad()\n            z = model(x.view(-1, 28 * 28))\n            loss = criterion(z, y)\n            loss.backward()\n            optimizer.step()\n            useful_stuff['training_loss'].append(loss.item())\n\n        correct = 0\n        for x, y in validation_loader:\n            z = model(x.view(-1, 28 * 28))\n            _, label=torch.max(z, 1)\n            correct += (label == y).sum().item()\n        accuracy = 100 * (correct / len(validation_dataset))\n        useful_stuff['validation_accuracy'].append(accuracy)\n\n    return useful_stuff","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<h2 id=\"Makeup_Data\">Make Some Data</h2> \n","metadata":{}},{"cell_type":"markdown","source":"Load the training dataset by setting the parameters <code>train</code> to <code>True</code> and convert it to a tensor by placing a transform object in the argument <code>transform</code>.\n","metadata":{}},{"cell_type":"code","source":"# Create the training dataset\n\ntrain_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load the testing dataset by setting the parameter <code>train</code> to <code>False</code> and convert it to a tensor by placing a transform object in the argument <code>transform</code>.\n","metadata":{}},{"cell_type":"code","source":"# Create the validation  dataset\n\nvalidation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the criterion function:  \n","metadata":{}},{"cell_type":"code","source":"# Create the criterion function\n\ncriterion = nn.CrossEntropyLoss()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the training-data loader and the validation-data loader object:\n","metadata":{}},{"cell_type":"code","source":"# Create the training data loader and validation data loader object\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<h2 id=\"Train\">Define the Neural Network, Criterion Function, Optimizer, and Train the Model</h2> \n","metadata":{}},{"cell_type":"markdown","source":"Create the criterion function: \n","metadata":{}},{"cell_type":"code","source":"# Create the criterion function\n\ncriterion = nn.CrossEntropyLoss()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the model with 100 hidden neurons:  \n","metadata":{}},{"cell_type":"code","source":"# Create the model object\n\ninput_dim = 28 * 28\nhidden_dim = 100\noutput_dim = 10\n\nmodel = Net(input_dim, hidden_dim, output_dim)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<h2 id=\"Test\">Test Sigmoid, Tanh, and Relu</h2> \n","metadata":{}},{"cell_type":"markdown","source":"Train the network by using the sigmoid activations function:\n","metadata":{}},{"cell_type":"code","source":"# Train a model with sigmoid function\n\nlearning_rate = 0.01\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\ntraining_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=30)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train the network by using the Tanh activations function:\n","metadata":{}},{"cell_type":"code","source":"# Train a model with Tanh function\n\nmodel_Tanh = NetTanh(input_dim, hidden_dim, output_dim)\noptimizer = torch.optim.SGD(model_Tanh.parameters(), lr=learning_rate)\ntraining_results_tanch = train(model_Tanh, criterion, train_loader, validation_loader, optimizer, epochs=30)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train the network by using the Relu activations function:\n","metadata":{}},{"cell_type":"code","source":"# Train a model with Relu function\n\nmodelRelu = NetRelu(input_dim, hidden_dim, output_dim)\noptimizer = torch.optim.SGD(modelRelu.parameters(), lr=learning_rate)\ntraining_results_relu = train(modelRelu, criterion, train_loader, validation_loader, optimizer, epochs=30)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<h2 id=\"Result\">Analyze Results</h2> \n","metadata":{}},{"cell_type":"markdown","source":"Compare the training loss for each activation: \n","metadata":{}},{"cell_type":"code","source":"# Compare the training loss\n\nplt.plot(training_results_tanch['training_loss'], label='tanh')\nplt.plot(training_results['training_loss'], label='sigmoid')\nplt.plot(training_results_relu['training_loss'], label='relu')\nplt.ylabel('loss')\nplt.title('training loss iterations')\nplt.legend()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Compare the validation loss for each model:  \n","metadata":{}},{"cell_type":"code","source":"# Compare the validation loss\n\nplt.plot(training_results_tanch['validation_accuracy'], label='tanh')\nplt.plot(training_results['validation_accuracy'], label='sigmoid')\nplt.plot(training_results_relu['validation_accuracy'], label='relu') \nplt.ylabel('validation accuracy')\nplt.xlabel('epochs ')\nplt.legend()\nplt.show()","metadata":{},"outputs":[],"execution_count":null}]}