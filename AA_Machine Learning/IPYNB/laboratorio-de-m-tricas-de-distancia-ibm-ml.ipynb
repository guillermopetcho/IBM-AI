{"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Distance Metrics**\n","metadata":{}},{"cell_type":"markdown","source":"Estimated time needed: **45** minutes\n","metadata":{}},{"cell_type":"markdown","source":"## Use cases of Distance Metrics\n\n- **Classification**: KNN model uses a distance metric to find a data point's top k nearest neighbors.\n- **Clustering**: K-Means algorithm assigns data points to the nearest centroids using a distance metric.\n- **Natural Language Processing**: NLP uses the cosine similarity distance metric to filter out irrelevant documents from the corpus once the unstructured data is transformed into vector form.\n","metadata":{"tags":[]}},{"cell_type":"markdown","source":"## Why different distance metrics matter?\n\nThere are many ways to define the distance between two objects. To give you a real-life example, suppose you want to go from one city to another on a map, there will be at least two different distances. One is the driving distance and the other could be the flying distance. Depending on how you choose to travel, one of the distances could make completely no sense to you. \n\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/images/distance.jpg\" width=\"60%\">\n\nImage from [PxHere](https://pxhere.com/en/photo/718584?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01)\n","metadata":{}},{"cell_type":"markdown","source":"Same idea applies to Machine Learning, choosing the correct distance metric is critical to the performance of the downstream task.\n\nIn this notebook, you will practice applying the distance metrics learned in this course. Using real-world data, you will analyze similarities and dissimilarities in data. You will also be able to understand how various algorithms such as DBSCAN are affected by different distance metrics.\n","metadata":{}},{"cell_type":"markdown","source":"## __Table of Contents__\n\n<!-- <a href=\"#Principle-Component-Analysis\">Principle Component Analysis</a> -->\n<ol>\n    <li><a href=\"#Objectives\">Objectives</a></li>\n    <li><a href=\"#Datasets\">Datasets</a></li>\n    <li>\n        <a href=\"#Setup\">Setup</a>\n        <ol>\n            <li><a href=\"#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n            <li><a href=\"#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n            <li><a href=\"#Defining-helper-functions\">Defining Helper Functions</a></li>\n        </ol>\n    </li>\n    <li>\n        <a href=\"#Euclidean-Distance\">Euclidean Distance</a>\n        <ol>\n            <li><a href=\"#euclidean_GE\">General Equation</a></li>\n        </ol>\n    </li>\n    <li>\n        <a href=\"#Manhattan-Distance\">Manhattan Distance</a>\n        <ol>\n            <li><a href=\"#manhattan_GE\">General Equation</a></li>\n        </ol>\n    </li>\n    <li>\n        <a href=\"#Cosine-Distance\">Cosine Distance</a>\n        <ol>\n            <li><a href=\"#cosine_GE\">General Equation</a></li>\n        </ol>\n    </li>\n    <li>\n        <a href=\"#Analyzing-Distance-Metrics-with-DBSCAN\">Analyzing Distance Metrics with DBSCAN</a>\n        <ol>\n            <li><a href=\"#DBSCAN-using-Euclidean:\">DBSCAN using Euclidean</a></li>\n        </ol>\n        <ol>\n            <li><a href=\"#DBSCAN-using-Manhattan:\">DBSCAN using Manhattan</a></li>\n        </ol>\n        <ol>\n            <li><a href=\"#DBSCAN-using-Cosine:\">DBSCAN using Cosine</a></li>\n        </ol>\n    </li>\n    <li>\n        <a href=\"#Jaccard-Distance\">Jaccard Distance</a>\n        <ol>\n            <li><a href=\"#jaccard_GE\">General Equation</a></li>\n        </ol>\n    </li>\n</ol>\n\n<a href=\"#Exercises\">Exercises</a>\n<ol>\n    <li><a href=\"#Exercise-1---Jaccard-distance\">Exercise 1 - Jaccard distance</a></li>\n    <li><a href=\"#Exercise-2---Euclidean-distance-and-manhattan-distance\">Exercise 2 - Euclidean distance and manhattan distance</a></li>\n    <li><a href=\"#Exercise-3---Cosine-distance\">Exercise 3 - Cosine Distance</a></li>\n    <li><a href=\"#Exercise-4---Using-sklearn.metrics.pairwise\">Exercise 4 - Using <code>sklearn.metrics.pairwise</code></a></li>\n</ol>\n","metadata":{}},{"cell_type":"markdown","source":"----\n","metadata":{}},{"cell_type":"markdown","source":"## Objectives\n","metadata":{}},{"cell_type":"markdown","source":"After completing this lab you will be able to:\n","metadata":{}},{"cell_type":"markdown","source":"* __Understand__ the mathematics behind the euclidean, manhattan, cosine, and jaccard distance metrics.\n* __Understand__ the use cases of the covered distance metrics.\n","metadata":{}},{"cell_type":"markdown","source":"## Datasets\n\nDatasets for this lab are gathered from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) under the MIT License.\n","metadata":{}},{"cell_type":"markdown","source":"## Setup\n","metadata":{}},{"cell_type":"markdown","source":"For this lab, we will be using the following libraries:\n - [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for managing the data.\n - [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for mathematical operations.\n - [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for visualizing the data.\n - [`scipy`](https://docs.scipy.org/doc/scipy/reference/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for complex numerical operations.\n - [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for machine learning and machine-learning-pipeline related functions.\n","metadata":{}},{"cell_type":"markdown","source":"### Installing Required Libraries\n\nThe following required modules are pre-installed in the Skills Network Labs environment. However if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda) you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n","metadata":{}},{"cell_type":"code","source":" # All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n#!mamba install -qy pandas==1.3.4 numpy==1.21.4 matplotlib==3.5.0 scipy==1.7.3\n!mamba install -qy scikit-learn==1.0.2\n# Note: If your environment doesn't support \"!mamba install\", use \"!pip install pandas==1.3.4 ... \"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Run the following cell to ensure you are using the correct version of sklearn:\n","metadata":{}},{"cell_type":"code","source":"import sklearn\nif sklearn.__version__ != \"1.0.2\":\n    raise ValueError(\"Please install sklearn==1.0.2 so this lab works properly\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Importing Required Libraries\n","metadata":{}},{"cell_type":"code","source":"# Surpress any warnings:\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\n\nimport pandas as pd\nimport numpy as np\nimport scipy\nfrom scipy.spatial.distance import euclidean, cityblock, cosine\nimport sklearn.metrics.pairwise\n\n# Import matplotlib for 3d plotting:\nimport matplotlib.pyplot as plt\n\n# Make matplotlib work in jupyter notebook\n%matplotlib inline","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Defining Helper Functions\n\nIn the section below, we will define helper functions that will help analyze different distance metrics\n\n__Average Distance__\n\nThis function will return the average distance between two sets of data given our provided distance metric, i.e., each point in $X$ with each other point in $Y$. Refer to the image below:\n\n\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/images/avg_distance.png\" width=\"30%\" height=\"auto/\">\n","metadata":{}},{"cell_type":"code","source":"# This function will allow us to find the average distance between two sets of data\ndef avg_distance(X1, X2, distance_func):\n    from sklearn.metrics import jaccard_score\n    #print(distance_func)\n    res = 0\n    for x1 in X1:\n        for x2 in X2:\n            if distance_func == jaccard_score: # the jaccard_score function only returns jaccard_similarity\n                res += 1 - distance_func(x1, x2)\n            else:\n                res += distance_func(x1, x2)\n    return res / (len(X1) * len(X2))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"__Pairwise Distance__\n\nThis function will return the average pairwise distance between two sets of data. The distance for each row in $X$ from the corresponding row in $Y$. The number of rows of in the two sets of data should be equal. Refer to the image below:\n\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/images/pairwise_distance.png\" width=\"30%\" height=\"auto\">\n","metadata":{}},{"cell_type":"code","source":"# This function will allow us to find the average pairwise distance\ndef avg_pairwise_distance(X1, X2, distance_func):\n    return sum(map(distance_func, X1, X2)) / min(len(X1), len(X2))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load the datafile into `pandas.DataFrame`\n\nBefore working with the data, it must be loaded into a `pandas.DataFrame`:\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/iris.csv')\ndf.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"For the purpose of this lab, we will not be using the `\"petal_width\"` column:\n","metadata":{}},{"cell_type":"code","source":"df.drop(['petal_width'], axis=1, inplace=True)\ndf.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's see what the different `\"species\"` types are in the dataset:\n","metadata":{}},{"cell_type":"code","source":"species = df['species'].unique()\nprint(species)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's view the three species of irises' data in 3D using `matplotlib`\n","metadata":{}},{"cell_type":"code","source":"attrs = ['sepal_length', 'sepal_width', 'petal_length']\nmarkers = ['o', 'v', '^']\nfig = plt.figure()\nax = fig.add_subplot(projection='3d')\nfor specie, marker in zip(species, markers):\n    specie_data = df.loc[df['species'] == specie][attrs]\n    xs, ys, zs = [specie_data[attr] for attr in attrs]\n    ax.scatter(xs, ys, zs, marker=marker)\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create variables for the species' data, as `np.ndarray`s:\n","metadata":{}},{"cell_type":"code","source":"setosa_data = df.loc[df['species'] == 'setosa'][attrs].to_numpy()\nversicolor_data = df.loc[df['species'] == 'versicolor'][attrs].to_numpy()\nvirginica_data = df.loc[df['species'] == 'virginica'][attrs].to_numpy()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In a the NumPy array, each point is a row and  each column is a dimension, we can see this by using <code>shape</code>:\n","metadata":{}},{"cell_type":"code","source":"setosa_data.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Euclidean Distance\n\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/images/euclidean.png\" width=\"30%\" height=\"auto/\">\n","metadata":{}},{"cell_type":"markdown","source":"In this task, you will learn and practice applying Euclidean distance.\n\nEuclidean distance is simply the physical distance between two points.\n\n_Euclidean distance is useful when physical distance matters most._\n\nWe know from high school math the distance between two points __on a plane (2D)__ $(x_1, y_1), (x_2, y_2)$ is:\n\n$\\sqrt{(x_2-x_1)^2 + (y_2-y_1)^2}$\n\nThe distance between two points in __3D__ $(x_1, y_1, z_1), (x_2, y_2, z_2)$ is:\n\n$\\sqrt{(x_2-x_1)^2 + (y_2-y_1)^2 + (z_2-z_1)^2}$\n\n### <a id='euclidean_GE'></a> General Equation\n\nThe __general equation for the euclidean distance__ between two points in n-dimentions $\\boldsymbol{a} = [a_1, a_2, \\dots, a_n], \\boldsymbol{b}=[b_1, b_2, \\dots, b_n]$ is:\n\n$$\\sqrt{\\sum_{i=1}^{n} (b_i-a_i)^2}$$\n\nOr for those inclined to Linear Algebra:\n\n$$|| \\boldsymbol{b} - \\boldsymbol{a} ||$$\n","metadata":{}},{"cell_type":"markdown","source":"We can use the function `euclidean` from `scipy.spatial.distance` to compute the euclidean distance between two points.\n","metadata":{}},{"cell_type":"code","source":"euclidean([0, 0], [3, 4])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Let's find the average _euclidean_ distance between the data of different species of irises\n\nAverage _euclidean_ distance between __setosa__ and __setosa__:\n","metadata":{"tags":[]}},{"cell_type":"markdown","source":"Average _euclidean_ distance between __setosa__ and __versicolor__:\n","metadata":{}},{"cell_type":"code","source":"avg_distance(setosa_data, versicolor_data, euclidean)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Average _euclidean_ distance between __setosa__ and __virginica__:\n","metadata":{}},{"cell_type":"code","source":"avg_distance(setosa_data, virginica_data, euclidean)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can also determine the  euclidean distances between two points using <code>paired_euclidean_distances</code> from <code>sklearn.metrics.pairwise</code>:\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics.pairwise import paired_euclidean_distances","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The input must be a numpy array where each point is a row:\n","metadata":{}},{"cell_type":"code","source":"X = np.array([[0, 0]], dtype=float)\nY = np.array([[3, 4]], dtype=float)\npaired_euclidean_distances(X, Y).mean()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We apply our own version of the function\n","metadata":{}},{"cell_type":"code","source":"avg_pairwise_distance(X, Y, euclidean)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If we have 2 MxN arrays, where each row is one of M points and each column is N dimensions in two arrays:\n","metadata":{}},{"cell_type":"code","source":"M, N = setosa_data.shape\nprint(f'{M} points and each column is {N} dimensions')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As above, we can calculate the distance between each array, then average the distance as follows. \nFirst, we calculate the distance between each row:\n","metadata":{}},{"cell_type":"code","source":"row_dist=paired_euclidean_distances(setosa_data, versicolor_data)\nrow_dist","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Then, we find the average value:\n","metadata":{}},{"cell_type":"code","source":"row_dist.mean()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We repeat the process:\n","metadata":{}},{"cell_type":"code","source":"paired_euclidean_distances(setosa_data, virginica_data).mean()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, applying our own function:\n","metadata":{}},{"cell_type":"code","source":"avg_pairwise_distance(setosa_data, virginica_data, euclidean)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Manhattan Distance\n\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/images/manhattan.png\" width=\"30%\" height=\"auto/\">\n","metadata":{}},{"cell_type":"markdown","source":"In this task, you will learn and practice applying Manhattan distance, sometimes called the  $L1$ norm and \"cityblock\" distance. The  Manhattan distance is even simpler than euclidean distance.\n\nIt can be described as the sum of the absolute value of the difference in each dimention of two points.\n\n_Manhattan distance can be preferrable to euclidean distance in high-dimentional situations._\n\nThe Manhattan distance between two points __on a plane (2D)__ $(x_1, y_1), (x_2, y_2)$ is:\n\n$|x_2 - x_1| + |y_2-y_1|$\n\n### <a id='manhattan_GE'></a> General Equation\n\nThe __general equation for the manhattan distance__ between two points in N-dimentions $\\boldsymbol{a}=[a_1, a_2, \\dots, a_n], \\boldsymbol{b}=[b_1, b_2, \\dots, b_n]$ is:\n\n$$ \\sum_{i=1}^{n} |b_i-a_i| $$\n","metadata":{}},{"cell_type":"markdown","source":"We can use the function `cityblock` from `scipy.spatial.distance` to compute the manhattan distance between two points.\n","metadata":{}},{"cell_type":"code","source":"cityblock([1, 1], [-2, 2])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Let's find the average _manhattan_ distance between the data of different species of irises\n\nAverage _manhattan_ distance between __setosa__ and __setosa__:\n","metadata":{}},{"cell_type":"code","source":"avg_distance(setosa_data, setosa_data, cityblock)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Average _manhattan_ distance between __setosa__ and __versicolor__:\n","metadata":{}},{"cell_type":"code","source":"avg_distance(setosa_data, versicolor_data, cityblock)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Average _manhattan_ distance between __setosa__ and __virginica__:\n","metadata":{}},{"cell_type":"code","source":"avg_distance(setosa_data, virginica_data, cityblock)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can also determine the pairwise Manhattan Distances between two points using <code>manhattan_distances</code> from <code>sklearn.metrics.pairwise</code>:\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics.pairwise import manhattan_distances","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = np.array([[1, 1]])\n\nY = np.array([[-2, 2]])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"manhattan_distances(X, Y)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cosine Distance\n\n<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/images/cosine.png\" width=\"30%\" height=\"auto/\">\n","metadata":{}},{"cell_type":"markdown","source":"In this task, you will learn and practice applying Cosine distance.\n\nThe cosine distance between two points can be thought of as one minus the cosine of the angle between them with respect to the origin.\n\nAs such, it has a value in the range $[0, 2]$ where:\n * $0$ means \"in the same direction\"\n * $1$ means \"perpendicular\"\n * $2$ means \"in the opposite direction.\"\n \nSo, **the lower the cosine distance, the more-similar two points are (in direction)**.\n\n_Cosine distance is useful when \"direction\" matters more than euclidean distance_\n\nThe cosine distance between two points __on a plane (2D)__ $(x_1, y_1), (x_2, y_2)$ is:\n\n$$1 - \\frac{x_1 \\cdot x_2 + y_1 \\cdot y_2}{\\sqrt{x_1^2 + y_1^2} + \\sqrt{x_2^2 + y_2^2}}$$\n\n### <a id='cosine_GE'></a> General Equation\n\nThe __general equation for the cosine distance__ between two points in N-dimentions $\\boldsymbol{a} = [a_1, a_2, \\dots, a_n], \\boldsymbol{b} = [b_1, b_2, \\dots, b_n]$ is:\n\n$$1 - \\frac{\\sum_{i=1}^{n} a_i \\cdot b_i}{\\sqrt{\\sum_{i=1}^{n} a_i^2} + \\sqrt{\\sum_{i=1}^{n} b_i^2}}$$\n\nOr for those inclined to linear algebra:\n\n$$1 - \\frac{\\boldsymbol{a} \\cdot \\boldsymbol{b}}{||\\boldsymbol{a}|| \\cdot ||\\boldsymbol{b}||}$$\n","metadata":{}},{"cell_type":"markdown","source":"We can use the function `cosine` from `scipy.spatial.distance` to compute the cosine distance between two points.\n","metadata":{}},{"cell_type":"code","source":"cosine([1, 1], [-1, -1])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"For this exercise, we will use a different dataset.\n\nDownload the dataset `\"auto-mpg.data\"`, which contains information about cars from 1970 to 1982:\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\n    'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/auto-mpg.data',\n    header=None, delim_whitespace=True,\n    names=['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name'])\ndf.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"For this example we are only using the `\"mpg\"` and `\"weight\"` features:\n","metadata":{}},{"cell_type":"code","source":"df['car_name'] = df['car_name'].str.split(n=1).apply(lambda lst: lst[0]).replace('chevrolet', 'chevy')\ndf.rename(columns={'car_name': 'make'}, inplace=True)\ndf = df[['mpg', 'weight', 'make']]\ndf.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Normalize** the numerical data (important for cosine distance if you want features to have \"equal weight\")\n","metadata":{}},{"cell_type":"code","source":"dfn = df[['mpg', 'weight']]\ndf[['mpg', 'weight']] = (dfn-dfn.min())/(dfn.max()-dfn.min())\ndf.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's use _cosine_ distance to compare chevy and honda makes from 1970 to 1982:\n","metadata":{}},{"cell_type":"code","source":"chevy = df.loc[df['make'] == 'chevy']\nhonda = df.loc[df['make'] == 'honda']\n\nplt.scatter(chevy['mpg'], chevy['weight'], marker='o', label='chevy')\nplt.scatter(honda['mpg'], honda['weight'], marker='^', label='honda')\nplt.xlabel('mpg')\nplt.ylabel('weight')\nplt.legend()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now let's analyze the data using _cosine_ distance.\n","metadata":{}},{"cell_type":"code","source":"chevy_data = chevy[['mpg', 'weight']].to_numpy()\nhonda_data = honda[['mpg', 'weight']].to_numpy()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The average _cosine_ distance between __chevy__ and __chevy__ makes:\n","metadata":{}},{"cell_type":"code","source":"avg_distance(chevy_data, chevy_data, cosine)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The average _cosine_ distance between __honda__ and __honda__ makes:\n","metadata":{}},{"cell_type":"code","source":"avg_distance(honda_data, honda_data, cosine)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The average _cosine_ distance between __honda__ and __chevy__ makes:\n","metadata":{}},{"cell_type":"code","source":"avg_distance(honda_data, chevy_data, cosine)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can also determine the  pairwise cosine distance  between two points using <code>cosine_distances</code> from <code>sklearn.metrics.pairwise</code>:\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_distances","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = np.array([[1, 1]])\nY = np.array([[-1, -1]])\ncosine_distances(X, Y)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You can derive the cosine distance from the cosine similarity as follows \n\n**cosine_distance = 1 - cosine_similarity**\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\n1-cosine_similarity(X,Y)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The average pairwise _cosine_ distance between __chevy__ and __chevy__ makes:\n","metadata":{}},{"cell_type":"code","source":"cosine_distances(chevy_data, chevy_data).mean()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" between __honda__ and __chevy__ makes:\n","metadata":{}},{"cell_type":"code","source":"cosine_distances(honda_data, chevy_data).mean()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Analyzing Distance Metrics with DBSCAN\n\nNow that we've learned various ___numerical___ distance metrics, let's see how they affect a clustering algorithm.\n\nWe begin by importing the `DBSCAN` object from `sklearn.neighbors` and downloading a synthetic dataset for clustering:\n","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import DBSCAN\ndf = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/data/synthetic_clustering.csv')\ndf.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.scatter(df['x'], df['y'])\nplt.xlabel('x')\nplt.ylabel('y')\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### DBSCAN using Euclidean:\n","metadata":{}},{"cell_type":"code","source":"dbscan = DBSCAN(eps=0.1, metric=euclidean)\ndbscan.fit(df)\ncolors = np.random.random(size=3*(dbscan.labels_.max()+1)).reshape(-1, 3)\nplt.scatter(df['x'], df['y'], c=[colors[l] for l in dbscan.labels_])\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### DBSCAN using Manhattan:\n","metadata":{}},{"cell_type":"code","source":"dbscan = DBSCAN(eps=0.1, metric=cityblock)\ndbscan.fit(df)\ncolors = np.random.random(size=3*(dbscan.labels_.max()+1)).reshape(-1, 3)\nplt.scatter(df['x'], df['y'], c=[colors[l] for l in dbscan.labels_])\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### DBSCAN using Cosine:\n","metadata":{}},{"cell_type":"code","source":"dbscan = DBSCAN(eps=0.1, metric=cosine)\ndbscan.fit(df)\ncolors = np.random.random(size=3*(dbscan.labels_.max()+1)).reshape(-1, 3)\nplt.scatter(df['x'], df['y'], c=[colors[l] for l in dbscan.labels_])\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Clearly, euclidean and manhattan distances have very similar results.\n\nHowever, using cosine distance, DBSCAN groups points based on their angle, leading to unique results which is some cases may be very useful.\n","metadata":{}},{"cell_type":"markdown","source":"## Jaccard Distance\n","metadata":{}},{"cell_type":"markdown","source":"In this task, you will learn and practice applying Jaccard distance.\n\nThe Jaccard distance is used to compute the dissimilarity/distance of two sets of objects.\n\nThe Jaccard distance between two sets is a value in the range $[0, 1]$ where:\n * $1$ means the two sets have nothing in common.\n * $0$ means the two sets are identical.\n \nSo **the greater the jaccard distance, the less similar the sets**.\n\n_Jaccard distance is useful when comparing two sets of (usually) non-numerical objects_\n\n### <a id='jaccard_GE'></a> General Equation\n\nThe __general equation for the jaccard distance__ between two sets $A$ and $B$ is:\n\n$$1 - \\frac{|A \\cap B|}{|A \\cup B|}$$\n\n * $\\cap$ means \"set intersection\"\n * $\\cup$ means \"union\"\n * $| S |$ means the \"length of set $S$\"\n","metadata":{"tags":[]}},{"cell_type":"markdown","source":"We can use `sklearn.metrics.jaccard_score` to compute the jaccard distance between categorical data. \n\n**NOTE**: `sklearn.metrics.jaccard_score` calculates the **jaccard similarity score**, which is **1 - jaccard distance**.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import jaccard_score","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"For this exercise, we will use a different dataset.\n\nDownload the dataset `\"breast-cancer.data\"` which contains information about people diagnosed with breast cancer:\n","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\n    'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/breast-cancer.data',\n    header=None,\n    names=['Class', 'age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig', 'breast', 'breast-quad', 'irradiat'])\ndf.head()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Lets look at the unique age groups in this dataset:\n","metadata":{}},{"cell_type":"code","source":"print(sorted(df['age'].unique()))\nprint(df.age.value_counts())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"As you can see, the data values are __categorical__ rather than real numerical values.\n\nTo obtain the **average jaccard distance** between two dataframes (**df1, df2**), we first need to convert the categorical variables into one-hot encoded (binary) variables. This allows us to easily compute the individual jaccard distance between each row in **df1** and other row in **df2**, since we could just view the rows as sets that contain 0's and 1's.\n\nWe can achieve this using the `OneHotEncoder` from `sklearn.preprocessing`:\n","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nOH = OneHotEncoder()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = OH.fit_transform(df.loc[:, df.columns != 'age']).toarray()\nprint(f\"By using onehot encoding, we obtained a 2d array with shape {X.shape} that only has value 0 and 1 \")","metadata":{"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We will be analyzing the _Jaccard_ distance of the set of people aged 30-39 and aged 60-69.\n","metadata":{}},{"cell_type":"code","source":"X30to39 = X[df[df.age == '30-39'].index]\nX60to69 = X[df[df.age == '60-69'].index]\n\nX30to39.shape, X60to69.shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Average Jaccard distance between people aged __30-39__ and __30-39__:\n","metadata":{}},{"cell_type":"code","source":"avg_distance(X30to39, X30to39, jaccard_score)","metadata":{"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Average Jaccard distance between people aged __60-69__ and __60-69__:\n","metadata":{}},{"cell_type":"code","source":"avg_distance(X60to69, X60to69, jaccard_score)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Average Jaccard distance between people aged __30-39__ and __60-69__:\n","metadata":{}},{"cell_type":"code","source":"avg_distance(X30to39, X60to69, jaccard_score)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Therefore, it seems there are some disparate trends between the 30-39 and 60-69 age groups.\n","metadata":{}},{"cell_type":"markdown","source":"# Exercises\n","metadata":{}},{"cell_type":"markdown","source":"## Exercise 1 - Jaccard distance\n","metadata":{"tags":[]}},{"cell_type":"code","source":"# Find the jaccard distance between the words in the following two sentences:\nsentence1 = 'Hello everyone and welcome to distance metrics'\nsentence2 = 'Hello world and welcome to distance metrics'","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"s1set = set(sentence1.split())\ns2set = set(sentence2.split())\nans = len(s1set.intersection(s2set)) / len(s1set.union(s2set))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Exercise 2 - Euclidean distance and manhattan distance\n","metadata":{}},{"cell_type":"code","source":"# Find the absolute value of the difference between the euclidean and manhattan distances of the two 3D points:\np1 = np.array([4, -3, 1])\np2 = np.array([-5, 1, -7])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import scipy.special\neuclidean = scipy.spatial.distance.euclidean(p1, p2)\nmanhattan = scipy.spatial.distance.cityblock(p1, p2)\nans = abs(manhattan - euclidean)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Exercise 3 - Cosine distance\n","metadata":{}},{"cell_type":"code","source":"# Find the cosine distance between the following two points:\np1 = np.array([1, 2, 3]).reshape(1, -1)\np2 = np.array([-2, -4, -6]).reshape(1, -1)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ans = cosine_distances(p1, p2)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Exercise 4 - Using `sklearn.metrics.pairwise`\n","metadata":{}},{"cell_type":"markdown","source":"Use:\n\n - [`sklearn.metrics.pairwise.paired_euclidean_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.paired_euclidean_distances.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01#sklearn.metrics.pairwise.paired_euclidean_distances)\n - [`sklearn.metrics.pairwise.paired_manhattan_distances`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.paired_manhattan_distances.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01#sklearn.metrics.pairwise.paired_manhattan_distances)\n\n\nto find the __pairwise__ distance between the following two datasets:\n","metadata":{}},{"cell_type":"code","source":"X1 = np.arange(8).reshape(4, 2)\nX2 = np.arange(8)[::-1].reshape(4, 2)\nprint(f'X1:\\n{X1}')\nprint(f'X2:\\n{X2}')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"paired_euclidean = sklearn.metrics.pairwise.paired_euclidean_distances(X1, X2)\npaired_manhattan = sklearn.metrics.pairwise.paired_manhattan_distances(X1, X2)","metadata":{},"outputs":[],"execution_count":null}]}