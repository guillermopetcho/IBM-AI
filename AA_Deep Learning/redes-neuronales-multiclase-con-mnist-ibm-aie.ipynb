{"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"1e34c38a1f888b90606106c7754bb2a3701f24cf757893feee6499e49d3c2289","kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Neural Networks with One Hidden Layer</h1>\n","metadata":{}},{"cell_type":"markdown","source":"<h2>Objective</h2><ul><li> How to classify handwritten digits using Neural Network.</li></ul> \n","metadata":{}},{"cell_type":"markdown","source":"<h2>Table of Contents</h2>\n<p>In this lab, you will use a single layer neural network to classify handwritten digits from the MNIST database.</p>\n\n<ul>\n    <li><a href=\"#Model\">Neural Network Module and Training Function</a></li>\n    <li><a href=\"#Makeup_Data\">Make Some Data</a></li>\n    <li><a href=\"#Train\">Define the Neural Network, Optimizer, and Train the  Model</a></li>\n    <li><a href=\"#Result\">Analyze Results</a></li>\n</ul>\n<p>Estimated Time Needed: <strong>25 min</strong></p>\n\n<hr>\n","metadata":{}},{"cell_type":"markdown","source":"<h2>Preparation</h2>\n","metadata":{}},{"cell_type":"markdown","source":"We'll need the following libraries\n","metadata":{}},{"cell_type":"code","source":"# Import the libraries we need for this lab\n\n# Using the following line code to install the torchvision library\n# !mamba install -y torchvision\n\nimport torch \nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\nimport torch.nn.functional as F\nimport matplotlib.pylab as plt\nimport numpy as np","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Use the following helper functions for plotting the loss: \n","metadata":{}},{"cell_type":"code","source":"# Define a function to plot accuracy and loss\n\ndef plot_accuracy_loss(training_results): \n    plt.subplot(2, 1, 1)\n    plt.plot(training_results['training_loss'], 'r')\n    plt.ylabel('loss')\n    plt.title('training loss iterations')\n    plt.subplot(2, 1, 2)\n    plt.plot(training_results['validation_accuracy'])\n    plt.ylabel('accuracy')\n    plt.xlabel('epochs')   \n    plt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Use the following function for printing the model parameters: \n","metadata":{}},{"cell_type":"code","source":"# Define a function to plot model parameters\n\ndef print_model_parameters(model):\n    count = 0\n    for ele in model.state_dict():\n        count += 1\n        if count % 2 != 0:\n            print (\"The following are the parameters for the layer \", count // 2 + 1)\n        if ele.find(\"bias\") != -1:\n            print(\"The size of bias: \", model.state_dict()[ele].size())\n        else:\n            print(\"The size of weights: \", model.state_dict()[ele].size())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define the neural network module or class: \n","metadata":{}},{"cell_type":"code","source":"# Define a function to display data\n\ndef show_data(data_sample):\n    plt.imshow(data_sample.numpy().reshape(28, 28), cmap='gray')\n    plt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name=\"Model\"><h2 id=\"Model\">Neural Network Module and Training Function</h2></a>\n","metadata":{}},{"cell_type":"markdown","source":"Define the neural network module or class: \n","metadata":{}},{"cell_type":"code","source":"# Define a Neural Network class\n\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n\n    # Prediction    \n    def forward(self, x):\n        x = torch.sigmoid(self.linear1(x))  \n        x = self.linear2(x)\n        return x","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define a function to train the model. In this case, the function returns a Python dictionary to store the training loss and accuracy on the validation data. \n","metadata":{}},{"cell_type":"code","source":"# Define a training function to train the model\n\ndef train(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n    i = 0\n    useful_stuff = {'training_loss': [],'validation_accuracy': []}  \n    for epoch in range(epochs):\n        for i, (x, y) in enumerate(train_loader): \n            optimizer.zero_grad()\n            z = model(x.view(-1, 28 * 28))\n            loss = criterion(z, y)\n            loss.backward()\n            optimizer.step()\n             #loss for every iteration\n            useful_stuff['training_loss'].append(loss.data.item())\n        correct = 0\n        for x, y in validation_loader:\n            #validation \n            z = model(x.view(-1, 28 * 28))\n            _, label = torch.max(z, 1)\n            correct += (label == y).sum().item()\n        accuracy = 100 * (correct / len(validation_dataset))\n        useful_stuff['validation_accuracy'].append(accuracy)\n    return useful_stuff","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name=\"Makeup_Data\"><h2 id=\"Makeup_Data\">Make Some Data</h2></a> \n","metadata":{}},{"cell_type":"markdown","source":"Load the training dataset by setting the parameters <code>train</code> to <code>True</code> and convert it to a tensor by placing a transform object in the argument <code>transform</code>.\n","metadata":{}},{"cell_type":"code","source":"# Create training dataset\n\ntrain_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load the testing dataset and convert it to a tensor by placing a transform object in the argument <code>transform</code>:\n","metadata":{}},{"cell_type":"code","source":"# Create validating dataset\n\nvalidation_dataset = dsets.MNIST(root='./data', download=True, transform=transforms.ToTensor())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the criterion function:  \n","metadata":{}},{"cell_type":"code","source":"# Create criterion function\n\ncriterion = nn.CrossEntropyLoss()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create the training-data loader and the validation-data loader objects: \n","metadata":{}},{"cell_type":"code","source":"# Create data loader for both train dataset and valdiate dataset\n\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000, shuffle=True)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000, shuffle=False)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name =\"Train\"><h2 id=\"Train\">Define the Neural Network, Optimizer, and Train the Model</h2></a> \n","metadata":{}},{"cell_type":"markdown","source":"Create the model with 100 neurons: \n","metadata":{}},{"cell_type":"code","source":"# Create the model with 100 neurons\n\ninput_dim = 28 * 28\nhidden_dim = 100\noutput_dim = 10\n\nmodel = Net(input_dim, hidden_dim, output_dim)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Print the model parameters: \n","metadata":{}},{"cell_type":"code","source":"# Print the parameters for model\n\nprint_model_parameters(model)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define the optimizer object with a learning rate of 0.01: \n","metadata":{}},{"cell_type":"code","source":"# Set the learning rate and the optimizer\n\nlearning_rate = 0.01\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train the model by using 100 epochs **(this process takes time)**: \n","metadata":{}},{"cell_type":"code","source":"# Train the model\n\ntraining_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=30)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"<a name=\"Result\"><h2 id=\"Result\">Analyze Results</h2></a> \n","metadata":{}},{"cell_type":"markdown","source":"Plot the training total loss or cost for every iteration and plot the training accuracy for every epoch:  \n","metadata":{}},{"cell_type":"code","source":"# Plot the accuracy and loss\n\nplot_accuracy_loss(training_results)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Plot the first five misclassified samples:   \n","metadata":{}},{"cell_type":"code","source":"# Plot the first five misclassified samples\n\ncount = 0\nfor x, y in validation_dataset:\n    z = model(x.reshape(-1, 28 * 28))\n    _,yhat = torch.max(z, 1)\n    if yhat != y:\n        show_data(x)\n        count += 1\n    if count >= 5:\n        break","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3>Practice</h3> \n","metadata":{}},{"cell_type":"markdown","source":"Use <code>nn.Sequential</code> to build exactly the same model as you just built. Use the function <train>train</train> to train the model and use the function <code>plot_accuracy_loss</code> to see the metrics. Also, try different epoch numbers. \n","metadata":{}},{"cell_type":"code","source":"# Practice: Use nn.Sequential to build the same model. Use plot_accuracy_loss to print out the accuarcy and loss\n\n# Type your code here\ninput_dim = 28 * 28\nhidden_dim = 100\noutput_dim = 10\n\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(input_dim, hidden_dim),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(hidden_dim, output_dim),\n)\nlearning_rate = 0.01\noptimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\ntraining_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs = 10)\nplot_accuracy_loss(training_results)","metadata":{},"outputs":[],"execution_count":null}]}