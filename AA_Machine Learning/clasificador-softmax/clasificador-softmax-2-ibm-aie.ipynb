{"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"6ad6da2a23b7826f1f4af138d4ae17c57611fa52e7e16a1cf4b69824709834d5","kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>Softmax Classifier</h1>\n","metadata":{}},{"cell_type":"markdown","source":"<h2>Objective</h2><ul><li> How to classify handwritten digits from the MNIST database by using Softmax classifier.</li></ul> \n","metadata":{}},{"cell_type":"markdown","source":"<h2>Table of Contents</h2>\n<p>In this lab, you will use a single layer Softmax to classify handwritten digits from the MNIST database.</p>\n\n<ul>\n    <li><a href=\"#Make-Some-Data\">Make some Data</a></li>\n    <li><a href=\"#Build-a-Softmax-Classifer\">Build a Softmax Classifer</a></li>\n    <li><a href=\"#Define-the-Softmax-Classifier,-Criterion-Function,-Optimizer,-and-Train-the-Model\">Define Softmax, Criterion Function, Optimizer, and Train the Model</a></li>\n    <li><a href=\"#Analyze-Results\">Analyze Results</a></li>\n</ul>\n<p>Estimated Time Needed: <strong>25 min</strong></p>\n\n<hr>\n","metadata":{}},{"cell_type":"markdown","source":"<h2>Preparation</h2>\n","metadata":{}},{"cell_type":"markdown","source":"We'll need the following libraries\n","metadata":{}},{"cell_type":"code","source":"# Import the libraries we need for this lab\n\n# Using the following line code to install the torchvision library\n# !mamba install -y torchvision\n\n!pip install torchvision==0.9.1 torch==1.8.1 \nimport torch \nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\nimport matplotlib.pylab as plt\nimport numpy as np","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Use the following function to plot out the parameters of the Softmax function:\n","metadata":{}},{"cell_type":"code","source":"# The function to plot parameters\n\ndef PlotParameters(model): \n    W = model.state_dict()['linear.weight'].data\n    w_min = W.min().item()\n    w_max = W.max().item()\n    fig, axes = plt.subplots(2, 5)\n    fig.subplots_adjust(hspace=0.01, wspace=0.1)\n    for i, ax in enumerate(axes.flat):\n        if i < 10:\n            \n            # Set the label for the sub-plot.\n            ax.set_xlabel(\"class: {0}\".format(i))\n\n            # Plot the image.\n            ax.imshow(W[i, :].view(28, 28), vmin=w_min, vmax=w_max, cmap='seismic')\n\n            ax.set_xticks([])\n            ax.set_yticks([])\n\n        # Ensure the plot is shown correctly with multiple plots\n        # in a single Notebook cell.\n    plt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Use the following function to visualize the data: \n","metadata":{}},{"cell_type":"code","source":"# Plot the data\n\ndef show_data(data_sample):\n    plt.imshow(data_sample[0].numpy().reshape(28, 28), cmap='gray')\n    plt.title('y = ' + str(data_sample[1]))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"## Make Some Data\n","metadata":{}},{"cell_type":"markdown","source":"Load the training dataset by setting the parameters <code>train</code> to <code>True</code> and convert it to a tensor by placing a transform object in the argument <code>transform</code>.\n","metadata":{}},{"cell_type":"code","source":"# Create and print the training dataset\n\ntrain_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\nprint(\"Print the training dataset:\\n \", train_dataset)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load the testing dataset and convert it to a tensor by placing a transform object in the argument <code>transform</code>.\n","metadata":{}},{"cell_type":"code","source":"# Create and print the validating dataset\n\nvalidation_dataset = dsets.MNIST(root='./data', download=True, transform=transforms.ToTensor())\nprint(\"Print the validating dataset:\\n \", validation_dataset)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You can see that the data type is long:\n","metadata":{}},{"cell_type":"code","source":"# Print the type of the element\n\nprint(\"Type of data element: \", type(train_dataset[0][1]))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Each element in the rectangular tensor corresponds to a number that represents a pixel intensity as demonstrated by the following image:\n","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.32_image_values.png\" width=\"550\" alt=\"MNIST elements\">\n","metadata":{}},{"cell_type":"markdown","source":"In this image, the values are inverted i.e back represents wight.\n","metadata":{}},{"cell_type":"markdown","source":"Print out the label of the fourth element:\n","metadata":{}},{"cell_type":"code","source":"# Print the label\n\nprint(\"The label: \", train_dataset[3][1])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The result shows the number in the image is 1\n","metadata":{}},{"cell_type":"markdown","source":"Plot  the fourth sample:\n","metadata":{}},{"cell_type":"code","source":"# Plot the image\n\nprint(\"The image: \", show_data(train_dataset[3]))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You see that it is a 1. Now, plot the third sample:\n","metadata":{}},{"cell_type":"code","source":"# Plot the image\n\nshow_data(train_dataset[2])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"## Build a Softmax Classifer\n","metadata":{}},{"cell_type":"markdown","source":"Build a Softmax classifier class: \n","metadata":{}},{"cell_type":"code","source":"# Define softmax classifier class\n\nclass SoftMax(nn.Module):\n    \n    # Constructor\n    def __init__(self, input_size, output_size):\n        super(SoftMax, self).__init__()\n        self.linear = nn.Linear(input_size, output_size)\n        \n    # Prediction\n    def forward(self, x):\n        z = self.linear(x)\n        return z","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The Softmax function requires vector inputs. Note that the vector shape is 28x28.\n","metadata":{}},{"cell_type":"code","source":"# Print the shape of train dataset\n\ntrain_dataset[0][0].shape","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Flatten the tensor as shown in this image: \n","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.3.2image_to_vector.gif\" width=\"550\" alt=\"Flattern Image\">\n","metadata":{}},{"cell_type":"markdown","source":"The size of the tensor is now 784.\n","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.3.2Imagetovector2.png\" width=\"550\" alt=\"Flattern Image\">\n","metadata":{}},{"cell_type":"markdown","source":"Set the input size and output size: \n","metadata":{}},{"cell_type":"code","source":"# Set input size and output size\n\ninput_dim = 28 * 28\noutput_dim = 10","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"## Define the Softmax Classifier, Criterion Function, Optimizer, and Train the Model\n","metadata":{}},{"cell_type":"code","source":"# Create the model\n\nmodel = SoftMax(input_dim, output_dim)\nprint(\"Print the model:\\n \", model)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"View the size of the model parameters: \n","metadata":{}},{"cell_type":"code","source":"# Print the parameters\n\nprint('W: ',list(model.parameters())[0].size())\nprint('b: ',list(model.parameters())[1].size())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You can cover the model parameters for each class to a rectangular grid:  \n","metadata":{}},{"cell_type":"markdown","source":"<a>     <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter3/3.3.2paramaters_to_image.gif\" width=\"550,\" align=\"center\"></a> \n","metadata":{}},{"cell_type":"markdown","source":"Plot the model parameters for each class as a square image: \n","metadata":{}},{"cell_type":"code","source":"# Plot the model parameters for each class\n\nPlotParameters(model)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define the learning rate, optimizer, criterion, data loader:\n","metadata":{}},{"cell_type":"code","source":"# Define the learning rate, optimizer, criterion and data loader\n\nlearning_rate = 0.1\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\ncriterion = nn.CrossEntropyLoss()\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train the model and determine validation accuracy **(should take a few minutes)**: \n","metadata":{}},{"cell_type":"code","source":"# Train the model\n\nn_epochs = 10\nloss_list = []\naccuracy_list = []\nN_test = len(validation_dataset)\n\ndef train_model(n_epochs):\n    for epoch in range(n_epochs):\n        for x, y in train_loader:\n            optimizer.zero_grad()\n            z = model(x.view(-1, 28 * 28))\n            loss = criterion(z, y)\n            loss.backward()\n            optimizer.step()\n            \n        correct = 0\n        # perform a prediction on the validationdata  \n        for x_test, y_test in validation_loader:\n            z = model(x_test.view(-1, 28 * 28))\n            _, yhat = torch.max(z.data, 1)\n            correct += (yhat == y_test).sum().item()\n        accuracy = correct / N_test\n        loss_list.append(loss.data)\n        accuracy_list.append(accuracy)\n\ntrain_model(n_epochs)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"## Analyze Results\n","metadata":{}},{"cell_type":"markdown","source":"Plot the loss and accuracy on the validation data:\n","metadata":{}},{"cell_type":"code","source":"# Plot the loss and accuracy\n\nfig, ax1 = plt.subplots()\ncolor = 'tab:red'\nax1.plot(loss_list,color=color)\nax1.set_xlabel('epoch',color=color)\nax1.set_ylabel('total loss',color=color)\nax1.tick_params(axis='y', color=color)\n    \nax2 = ax1.twinx()  \ncolor = 'tab:blue'\nax2.set_ylabel('accuracy', color=color)  \nax2.plot( accuracy_list, color=color)\nax2.tick_params(axis='y', color=color)\nfig.tight_layout()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"View the results of the parameters for each class after the training. You can see that they look like the corresponding numbers. \n","metadata":{}},{"cell_type":"code","source":"# Plot the parameters\n\nPlotParameters(model)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We Plot the first five misclassified  samples and the probability of that class.\n","metadata":{}},{"cell_type":"code","source":"# Plot the misclassified samples\nSoftmax_fn=nn.Softmax(dim=-1)\ncount = 0\nfor x, y in validation_dataset:\n    z = model(x.reshape(-1, 28 * 28))\n    _, yhat = torch.max(z, 1)\n    if yhat != y:\n        show_data((x, y))\n        plt.show()\n        print(\"yhat:\", yhat)\n        print(\"probability of class \", torch.max(Softmax_fn(z)).item())\n        count += 1\n    if count >= 5:\n        break       ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<!--Empty Space for separating topics-->\n","metadata":{}},{"cell_type":"markdown","source":"We Plot the first five correctly classified samples and the probability of that class, we see the probability is much larger.\n","metadata":{}},{"cell_type":"code","source":"# Plot the classified samples\nSoftmax_fn=nn.Softmax(dim=-1)\ncount = 0\nfor x, y in validation_dataset:\n    z = model(x.reshape(-1, 28 * 28))\n    _, yhat = torch.max(z, 1)\n    if yhat == y:\n        show_data((x, y))\n        plt.show()\n        print(\"yhat:\", yhat)\n        print(\"probability of class \", torch.max(Softmax_fn(z)).item())\n        count += 1\n    if count >= 5:\n        break  ","metadata":{},"outputs":[],"execution_count":null}]}